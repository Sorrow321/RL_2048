{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import env.game as game\n",
    "\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from itertools import count\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_game = game.Game()\n",
    "ob = env_game.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, loss_batch, eps, reward_range=[50, 5000]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress.\n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    #threshold = np.percentile(rewards_batch, percentile)\n",
    "    #log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    #print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[12, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(rewards_batch, label=f'Average reward. Eps: {eps:.4f}')\n",
    "    #plt.plot(list(zip(*log))[1], label=\"Reward thresholds\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss_batch, label=\"Average loss\")\n",
    "    #plt.plot(list(zip(*log))[1], label=\"Reward thresholds\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    #plt.hist(rewards_batch, range=reward_range)\n",
    "    #plt.vlines(\n",
    "    #    [np.percentile(rewards_batch, percentile)],\n",
    "    ##    [0],\n",
    "    #   [100],\n",
    "    #    label=\"percentile\",\n",
    "    #    color=\"red\",\n",
    "    #)\n",
    "    #plt.legend()\n",
    "    #plt.grid()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 21])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define the function to encode the state of the 2048 game board\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def encode_board(board):\n",
    "    board = board.flatten()\n",
    "    max_power = 20  # Maximum power of 2 that can be represented\n",
    "    num_classes = max_power + 1  # Including 0, but we'll use zero vectors for empty tiles\n",
    "\n",
    "    # Compute the log2 of the board values where board > 0, set the rest to 0\n",
    "    powers = np.zeros_like(board, dtype=int)\n",
    "    non_zero_indices = board > 0\n",
    "    powers[non_zero_indices] = np.log2(board[non_zero_indices]).astype(int)\n",
    "\n",
    "    # One-hot encode the powers array\n",
    "    one_hot_encoded = np.eye(num_classes)[powers]\n",
    "    \n",
    "    # Set the one-hot encoded vectors corresponding to zero tiles to zero\n",
    "    one_hot_encoded[board == 0] = 0\n",
    "    \n",
    "    # Convert to tensor\n",
    "    one_hot_encoded_tensor = torch.tensor(one_hot_encoded, dtype=torch.float32)\n",
    "    \n",
    "    # Reshape to 4x4x21\n",
    "    one_hot_encoded_tensor = one_hot_encoded_tensor.view(4, 4, num_classes)\n",
    "    \n",
    "    return one_hot_encoded_tensor\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "board = np.array([[2, 4, 0, 2],\n",
    "                  [8, 0, 16, 32],\n",
    "                  [2, 4, 128, 0],\n",
    "                  [256, 0, 1024, 2048]])\n",
    "\n",
    "encoded_board = encode_board(board)\n",
    "print(encoded_board.shape)  # Should print (16, 21) indicating 16 tiles and 21 one-hot encoded features per tile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have an environment class 'Env' as described\n",
    "class Env:\n",
    "    def __init__(self, env_f):\n",
    "        self.env = env_f\n",
    "        \n",
    "    def action(self, a):\n",
    "        next_ob, r, term = self.env.action(a)\n",
    "        next_ob = np.array(next_ob)\n",
    "        encoded_next_ob = encode_board(next_ob)\n",
    "        return (encoded_next_ob.permute(2, 0, 1).unsqueeze(0), r, term)  # Reshape for CNN\n",
    "\n",
    "    def reset(self):\n",
    "        initial_state = self.env.reset()\n",
    "        initial_state = np.array(initial_state)\n",
    "        encoded_initial_state = encode_board(np.array(initial_state))\n",
    "        return encoded_initial_state.permute(2, 0, 1).unsqueeze(0)  # Reshape for CNN\n",
    "\n",
    "\n",
    "\n",
    "# Define the DQN network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=21, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(21 * 4 * 4, 512)  # After flattening from the conv layers\n",
    "        #self.fc2 = nn.Linear(512, 512)\n",
    "        #self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 64)\n",
    "        self.fc6 = nn.Linear(64, 4)  # Output layer (assuming 4 possible actions)\n",
    "        self.lin = nn.Linear(16, 4)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional layers with ReLU activations\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        \n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        \n",
    "        # Apply the fully connected layers with ReLU activations\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        #x = self.dropout(x)\n",
    "        #x = F.relu(self.fc4(x))\n",
    "        #x = self.dropout(x)\n",
    "        #x = F.relu(self.fc5(x))\n",
    "        #x = self.dropout(x)\n",
    "        \n",
    "        # Output layer (raw scores for each action)\n",
    "        #x = self.fc6(x)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TransformerDQN(nn.Module):\n",
    "    def __init__(self, num_tiles=21, d_model=64, nhead=4, num_layers=3, dim_feedforward=64):\n",
    "        super(TransformerDQN, self).__init__()\n",
    "\n",
    "        # Positional encoding for the 4x4 grid\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(16, d_model))\n",
    "\n",
    "        # Linear projection of the input one-hot vectors to the model dimension\n",
    "        self.input_proj = nn.Linear(num_tiles, d_model)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            batch_first=True  # Setting batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Fully connected layers after the transformer\n",
    "        self.fc1 = nn.Linear(16 * d_model, 4)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Reshape the input tensor to shape (batch_size, 16, 21)\n",
    "        x = x.reshape(batch_size, 21, -1)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # Apply the linear projection\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        # Add positional encoding\n",
    "        #x = x + self.positional_encoding\n",
    "\n",
    "        # Pass through the transformer encoder (batch_first=True ensures no need for transposing)\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Flatten the sequence output\n",
    "        x = x.contiguous().view(batch_size, -1)\n",
    "\n",
    "        # Pass through the fully connected layers\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "GAMMA = 0.5\n",
    "EPSILON_START = 0.99\n",
    "EPSILON_END = 0.2\n",
    "EPSILON_DECAY = 200000\n",
    "TARGET_UPDATE = 30\n",
    "MEMORY_SIZE = 5000\n",
    "LR = 1e-4\n",
    "\n",
    "class ExperienceReplay:\n",
    "    def __init__(self, capacity):\n",
    "        self.pointer = 0\n",
    "        self.capacity = capacity\n",
    "        self.states = torch.zeros((capacity, 21, 4, 4), device='cpu')\n",
    "        self.actions = torch.zeros((capacity, 1), dtype=torch.int64, device='cpu')\n",
    "        self.next_states = torch.zeros_like(self.states, device='cpu')\n",
    "        self.rewards = torch.zeros((capacity, 1), device='cpu')\n",
    "        self.dones = torch.zeros((capacity, 1), dtype=torch.int64, device='cpu')\n",
    "\n",
    "    def push(self, s, a, r, s_new, done):\n",
    "        tar_idx = self.pointer % self.capacity\n",
    "        self.states[tar_idx] = s.cpu()\n",
    "        self.actions[tar_idx] = a.cpu()\n",
    "        self.rewards[tar_idx] = r.cpu()\n",
    "        self.next_states[tar_idx] = s_new.cpu()\n",
    "        self.dones[tar_idx] = done\n",
    "        self.pointer += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        perm = torch.randperm(len(self))\n",
    "        tar_idxes = perm[:batch_size]\n",
    "        return (\n",
    "            self.states[tar_idxes].cuda(),\n",
    "            self.actions[tar_idxes].cuda(),\n",
    "            self.rewards[tar_idxes].cuda(),\n",
    "            self.next_states[tar_idxes].cuda(),\n",
    "            self.dones[tar_idxes].cuda(),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(self.pointer, self.capacity)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize environment, networks, optimizer, and memory\n",
    "env = Env(env_game) #gym.make(\"CartPole-v1\")\n",
    "policy_net = DQN().to(device)\n",
    "target_net = DQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, weight_decay=0)\n",
    "memory = ExperienceReplay(MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mem = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(state, epsilon):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    steps_done += 1\n",
    "    if sample > epsilon:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(4)]], dtype=torch.long, device=device)\n",
    "\n",
    "def optimize_model():\n",
    "    global dt0\n",
    "    global dt1\n",
    "\n",
    "    \n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return 0\n",
    "    t0 = time.time()\n",
    "    state_batch, action_batch, reward_batch, next_state_batch, done_batch = memory.sample(BATCH_SIZE)\n",
    "\n",
    "    Q_s = policy_net(state_batch).gather(1, action_batch)\n",
    "    with torch.no_grad():\n",
    "        # double dqn\n",
    "        best_actions = policy_net(next_state_batch).max(1)[1].unsqueeze(1) \n",
    "        Q_next = target_net(next_state_batch).gather(1, best_actions) * (1-done_batch)\n",
    "        #Q_next = target_net(next_state_batch).max(1)[0].unsqueeze(1).detach()\n",
    "\n",
    "    target = reward_batch + GAMMA * Q_next\n",
    "    loss = F.mse_loss(Q_s, target)\n",
    "    dt0 += time.time() - t0\n",
    "\n",
    "    t0 = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    dt1 += time.time() - t0\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = EPSILON_START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON_END = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_UPDATE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main training loop\n",
    "num_episodes = 2000000\n",
    "episode_durations = []\n",
    "rewards = []\n",
    "mean_rewards = []\n",
    "losses = []\n",
    "mean_losses = []\n",
    "\n",
    "dt0 = 0\n",
    "dt1 = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    state = torch.tensor(env.reset(), dtype=torch.float32, device=device)\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    if (i_episode + 1) % 200 == 0:\n",
    "        epsilon *= 2\n",
    "    \n",
    "    for t in count():\n",
    "        #print(state.shape)\n",
    "        epsilon = max(epsilon * 0.99995, EPSILON_END)\n",
    "        action = select_action(state, epsilon if t > 220 else 0.01)\n",
    "        \n",
    "        next_ob, reward, done = env.action(action.item())\n",
    "        if reward > 0:\n",
    "            #if reward >= 128:\n",
    "            #    reward = np.log2(reward)\n",
    "            #else:\n",
    "            #    reward = 0\n",
    "            reward = 1\n",
    "            #reward = np.log2(reward)\n",
    "        elif reward == 0:\n",
    "            reward = 0\n",
    "        else:\n",
    "            #reward = 0\n",
    "            reward = -1\n",
    "        total_reward += reward\n",
    "\n",
    "        reward = torch.tensor([reward], dtype=torch.float32, device=device)\n",
    "        next_state = torch.tensor(next_ob, dtype=torch.float32, device=device) if not done else None\n",
    "\n",
    "        memory.push(state, action, reward / 2, next_state if not done else state, done)\n",
    "        state_old = state\n",
    "        state = next_state\n",
    "        loss = optimize_model()\n",
    "        total_loss += loss\n",
    "        if done:\n",
    "            #print(state_old)\n",
    "            episode_durations.append(t + 1)\n",
    "            rewards.append(total_reward)\n",
    "            losses.append(total_loss)\n",
    "            mean_losses.append(np.mean(losses[-10:])/ 10000)\n",
    "            mean_rewards.append(np.mean(rewards[-10:]))  # Calculate mean reward of the last 100 episodes\n",
    "            break\n",
    "\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "    if i_episode % 10 == 0:\n",
    "        show_progress(mean_rewards[-500:], mean_losses[-500:], epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010124774649739265"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.271702787237217"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.036020040512085"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.723793029785156"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1489929/4086458684.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(env.reset(), dtype=torch.float32, device=device)\n"
     ]
    }
   ],
   "source": [
    "state = torch.tensor(env.reset(), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[0, :, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_board(encoded_board):\n",
    "    # encoded_board shape: [batch_size, 21, 4, 4] or [21, 4, 4] if not batched\n",
    "    # First, ensure that the encoded_board is in the correct shape\n",
    "    if encoded_board.dim() == 4:\n",
    "        # If the input is batched, remove the batch dimension\n",
    "        encoded_board = encoded_board.squeeze(0)\n",
    "    \n",
    "    # Permute the encoded board to shape [4, 4, 21] for easier decoding\n",
    "    encoded_board = encoded_board.permute(1, 2, 0)  # Now shape is [4, 4, 21]\n",
    "    \n",
    "    # Get the indices of the maximum values along the last dimension (the one-hot vector dimension)\n",
    "    powers = torch.argmax(encoded_board, dim=-1)\n",
    "    \n",
    "    # Convert the powers back to the corresponding values in the 2048 game board\n",
    "    decoded_board = torch.pow(2, powers).cpu().numpy()\n",
    "    \n",
    "    # Replace 2^0 (which is 1) with 0 to represent empty tiles\n",
    "    decoded_board[decoded_board == 1] = 0\n",
    "    \n",
    "    return decoded_board\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv1): Conv2d(21, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc6): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 2, 2],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_board(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 4, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State:\n",
      "[[0 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]]\n",
      "Q:  tensor([[ 0.4504,  0.6333, -0.0467,  0.3318]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[0 0 0 4]\n",
      " [0 0 0 0]\n",
      " [4 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[0 0 0 4]\n",
      " [0 0 0 0]\n",
      " [4 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Q:  tensor([[0.2544, 0.0643, 0.0668, 0.0749]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[0 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 0 0]\n",
      " [4 0 0 4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[0 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 0 0]\n",
      " [4 0 0 4]]\n",
      "Q:  tensor([[0.2731, 0.2244, 0.7838, 0.6919]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[0 2 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [0 0 0 8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[0 2 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [0 0 0 8]]\n",
      "Q:  tensor([[0.1897, 0.2556, 0.3823, 0.3709]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[0 0 0 2]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [2 0 0 8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[0 0 0 2]\n",
      " [0 0 0 2]\n",
      " [0 0 0 0]\n",
      " [2 0 0 8]]\n",
      "Q:  tensor([[0.7957, 0.6175, 0.0667, 0.2331]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[0 0 0 0]\n",
      " [2 0 0 0]\n",
      " [0 0 0 4]\n",
      " [2 0 0 8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[0 0 0 0]\n",
      " [2 0 0 0]\n",
      " [0 0 0 4]\n",
      " [2 0 0 8]]\n",
      "Q:  tensor([[0.5782, 0.6187, 0.4139, 0.3519]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[4 0 0 4]\n",
      " [0 0 0 8]\n",
      " [2 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[4 0 0 4]\n",
      " [0 0 0 8]\n",
      " [2 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Q:  tensor([[0.3647, 0.4278, 0.7786, 0.7807]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[8 0 0 0]\n",
      " [8 0 0 0]\n",
      " [2 0 2 0]\n",
      " [0 0 0 0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[8 0 0 0]\n",
      " [8 0 0 0]\n",
      " [2 0 2 0]\n",
      " [0 0 0 0]]\n",
      "Q:  tensor([[0.8046, 0.7031, 0.7374, 0.5472]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  2  0]\n",
      " [ 0  0  0  0]\n",
      " [16  0  0  0]\n",
      " [ 2  0  2  0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  2  0]\n",
      " [ 0  0  0  0]\n",
      " [16  0  0  0]\n",
      " [ 2  0  2  0]]\n",
      "Q:  tensor([[0.7433, 0.7319, 0.6484, 0.7570]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  0  0  0]\n",
      " [ 4  0  0  0]\n",
      " [16  0  0  0]\n",
      " [ 4  0  0  0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  0  0  0]\n",
      " [ 4  0  0  0]\n",
      " [16  0  0  0]\n",
      " [ 4  0  0  0]]\n",
      "Q:  tensor([[ 0.1563, -0.0960,  0.3329, -0.3501]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  4]\n",
      " [ 0  4  0 16]\n",
      " [ 0  0  0  4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  4]\n",
      " [ 0  4  0 16]\n",
      " [ 0  0  0  4]]\n",
      "Q:  tensor([[0.1375, 0.0705, 0.0646, 0.4131]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [ 4 16  0  0]\n",
      " [ 4  0  0  0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  0  0  0]\n",
      " [ 4  2  0  0]\n",
      " [ 4 16  0  0]\n",
      " [ 4  0  0  0]]\n",
      "Q:  tensor([[0.7507, 0.7969, 0.2588, 0.2576]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  2  0  2]\n",
      " [ 8 16  0  0]\n",
      " [ 4  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  2  0  2]\n",
      " [ 8 16  0  0]\n",
      " [ 4  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[0.2306, 0.3076, 0.6410, 0.8521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 4  2  0  0]\n",
      " [ 8 16  2  0]\n",
      " [ 4  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 4  2  0  0]\n",
      " [ 8 16  2  0]\n",
      " [ 4  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[ 0.2956,  0.2962,  0.3275, -0.1494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  4  2]\n",
      " [ 0  8 16  2]\n",
      " [ 2  0  0  4]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  4  2]\n",
      " [ 0  8 16  2]\n",
      " [ 2  0  0  4]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[0.9289, 0.8651, 0.2844, 0.4077]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  4  4]\n",
      " [ 2  8 16  4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  4  4]\n",
      " [ 2  8 16  4]]\n",
      "Q:  tensor([[0.8433, 0.6930, 0.7969, 0.7735]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  2]\n",
      " [ 0  0  4  2]\n",
      " [ 2  8 16  8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  0]\n",
      " [ 0  0  0  2]\n",
      " [ 0  0  4  2]\n",
      " [ 2  8 16  8]]\n",
      "Q:  tensor([[0.8567, 0.9408, 0.1606, 0.3828]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  8  4  4]\n",
      " [ 0  0 16  8]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  2  0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  8  4  4]\n",
      " [ 0  0 16  8]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  2  0]]\n",
      "Q:  tensor([[0.2891, 0.5662, 0.8991, 0.7807]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2  8  8]\n",
      " [ 0  0 16  8]\n",
      " [ 0  0  0  0]\n",
      " [ 0  4  0  2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2  8  8]\n",
      " [ 0  0 16  8]\n",
      " [ 0  0  0  0]\n",
      " [ 0  4  0  2]]\n",
      "Q:  tensor([[0.7827, 0.7567, 0.7571, 0.7144]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 0  2  8 16]\n",
      " [ 0  4 16  2]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 0  2  8 16]\n",
      " [ 0  4 16  2]]\n",
      "Q:  tensor([[0.1922, 0.3100, 0.2607, 0.3858]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 2  8 16  0]\n",
      " [ 4 16  2  2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 2  8 16  0]\n",
      " [ 4 16  2  2]]\n",
      "Q:  tensor([[0.8877, 0.8440, 0.7703, 0.9046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 2  8 16  0]\n",
      " [ 4 16  4  0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 2  8 16  0]\n",
      " [ 4 16  4  0]]\n",
      "Q:  tensor([[1.0391, 0.8379, 0.4595, 0.5483]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  0]\n",
      " [ 2  2  0  0]\n",
      " [ 4  8 16  0]\n",
      " [ 4 16  4  0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  0]\n",
      " [ 2  2  0  0]\n",
      " [ 4  8 16  0]\n",
      " [ 4 16  4  0]]\n",
      "Q:  tensor([[0.8504, 0.7493, 0.8053, 0.8315]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  0]\n",
      " [ 0  2  0  0]\n",
      " [ 2  8 16  0]\n",
      " [ 8 16  4  2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  0]\n",
      " [ 0  2  0  0]\n",
      " [ 2  8 16  0]\n",
      " [ 8 16  4  2]]\n",
      "Q:  tensor([[0.1119, 0.3994, 0.2600, 0.2972]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  2 16  2]\n",
      " [ 8  8  4  0]\n",
      " [ 2 16  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  2 16  2]\n",
      " [ 8  8  4  0]\n",
      " [ 2 16  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[0.2625, 0.1063, 0.7083, 0.8304]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 4 16  2  0]\n",
      " [16  4  0  0]\n",
      " [ 2 16  0  0]\n",
      " [ 0  0  2  0]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 4 16  2  0]\n",
      " [16  4  0  0]\n",
      " [ 2 16  0  0]\n",
      " [ 0  0  2  0]]\n",
      "Q:  tensor([[0.7221, 0.7829, 0.4085, 0.3706]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 4 16  4  0]\n",
      " [16  4  0  0]\n",
      " [ 2 16  0  0]\n",
      " [ 2  0  0  0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 4 16  4  0]\n",
      " [16  4  0  0]\n",
      " [ 2 16  0  0]\n",
      " [ 2  0  0  0]]\n",
      "Q:  tensor([[ 0.8215,  0.7631,  0.3883, -0.0115]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  0]\n",
      " [ 4 16  0  0]\n",
      " [16  4  2  0]\n",
      " [ 4 16  4  0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  0]\n",
      " [ 4 16  0  0]\n",
      " [16  4  2  0]\n",
      " [ 4 16  4  0]]\n",
      "Q:  tensor([[ 0.2368,  0.4962,  0.1323, -0.0018]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 4 16  2  2]\n",
      " [16  4  4  0]\n",
      " [ 4 16  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 4 16  2  2]\n",
      " [16  4  4  0]\n",
      " [ 4 16  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[0.6501, 0.5525, 0.8464, 0.7403]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  4 16  4]\n",
      " [ 2  0 16  8]\n",
      " [ 0  0  4 16]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  4 16  4]\n",
      " [ 2  0 16  8]\n",
      " [ 0  0  4 16]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[0.8432, 0.7925, 0.2476, 0.1647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2  0  0]\n",
      " [ 0  0  0  4]\n",
      " [ 0  0 32  8]\n",
      " [ 2  4  4 16]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2  0  0]\n",
      " [ 0  0  0  4]\n",
      " [ 0  0 32  8]\n",
      " [ 2  4  4 16]]\n",
      "Q:  tensor([[0.4991, 0.3352, 0.8761, 0.8098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  2]\n",
      " [ 0  2  0  4]\n",
      " [ 0  0 32  8]\n",
      " [ 0  2  8 16]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  2]\n",
      " [ 0  2  0  4]\n",
      " [ 0  0 32  8]\n",
      " [ 0  2  8 16]]\n",
      "Q:  tensor([[0.6901, 0.6730, 0.2800, 0.4925]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  2]\n",
      " [ 2  0  0  4]\n",
      " [ 0  0 32  8]\n",
      " [ 0  4  8 16]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  2]\n",
      " [ 2  0  0  4]\n",
      " [ 0  0 32  8]\n",
      " [ 0  4  8 16]]\n",
      "Q:  tensor([[0.2153, 0.3676, 0.3455, 0.3418]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  4 32  2]\n",
      " [ 2  0  8  4]\n",
      " [ 0  0  0  8]\n",
      " [ 0  0  0 16]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  4 32  2]\n",
      " [ 2  0  8  4]\n",
      " [ 0  0  0  8]\n",
      " [ 0  0  0 16]]\n",
      "Q:  tensor([[0.9237, 0.8490, 0.2418, 0.3193]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  0  0  2]\n",
      " [ 0  0  0  4]\n",
      " [ 0  0 32  8]\n",
      " [ 4  4  8 16]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  0  0  2]\n",
      " [ 0  0  0  4]\n",
      " [ 0  0 32  8]\n",
      " [ 4  4  8 16]]\n",
      "Q:  tensor([[0.3263, 0.3106, 0.8322, 0.9312]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 4  0  0  0]\n",
      " [ 4  0  0  2]\n",
      " [32  8  0  0]\n",
      " [ 8  8 16  0]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 4  0  0  0]\n",
      " [ 4  0  0  2]\n",
      " [32  8  0  0]\n",
      " [ 8  8 16  0]]\n",
      "Q:  tensor([[0.7986, 0.9262, 0.7630, 0.8505]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8 16 16  2]\n",
      " [32  2  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 24 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8 16 16  2]\n",
      " [32  2  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[0.2495, 0.1186, 0.7303, 0.8347]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8 32  2  0]\n",
      " [32  2  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 0  0  0  2]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8 32  2  0]\n",
      " [32  2  0  0]\n",
      " [ 8  0  0  0]\n",
      " [ 0  0  0  2]]\n",
      "Q:  tensor([[0.4062, 0.2784, 0.2801, 0.3088]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  0  0  0]\n",
      " [ 8  0  0  0]\n",
      " [32 32  0  0]\n",
      " [ 8  2  2  2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  0  0  0]\n",
      " [ 8  0  0  0]\n",
      " [32 32  0  0]\n",
      " [ 8  2  2  2]]\n",
      "Q:  tensor([[0.5452, 0.3910, 0.7503, 0.7138]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  8]\n",
      " [ 2  0  0 64]\n",
      " [ 0  8  2  4]]\n",
      "Reward: 68 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  2]\n",
      " [ 0  0  0  8]\n",
      " [ 2  0  0 64]\n",
      " [ 0  8  2  4]]\n",
      "Q:  tensor([[ 0.3819,  0.3373, -0.0508,  0.2197]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  2]\n",
      " [ 0  2  0  8]\n",
      " [ 0  0  0 64]\n",
      " [ 2  8  2  4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  2]\n",
      " [ 0  2  0  8]\n",
      " [ 0  0  0 64]\n",
      " [ 2  8  2  4]]\n",
      "Q:  tensor([[0.2365, 0.5300, 0.2120, 0.2261]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  2  2  2]\n",
      " [ 0  8  0  8]\n",
      " [ 0  0  0 64]\n",
      " [ 0  0  2  4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  2  2  2]\n",
      " [ 0  8  0  8]\n",
      " [ 0  0  0 64]\n",
      " [ 0  0  2  4]]\n",
      "Q:  tensor([[0.5107, 0.8373, 0.7867, 0.7883]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  2  4  2]\n",
      " [ 0  8  0  8]\n",
      " [ 0  0  0 64]\n",
      " [ 2  0  0  4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  2  4  2]\n",
      " [ 0  8  0  8]\n",
      " [ 0  0  0 64]\n",
      " [ 2  0  0  4]]\n",
      "Q:  tensor([[0.7026, 0.8987, 0.9724, 0.8611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  4  4  2]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 64]\n",
      " [ 2  0  2  4]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  4  4  2]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 64]\n",
      " [ 2  0  2  4]]\n",
      "Q:  tensor([[0.3844, 0.3916, 0.9193, 0.7969]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2  8  2]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 64]\n",
      " [ 0  0  4  4]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2  8  2]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 64]\n",
      " [ 0  0  4  4]]\n",
      "Q:  tensor([[0.4080, 0.2489, 0.6123, 0.6362]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  8  2  0]\n",
      " [16  2  0  0]\n",
      " [64  0  0  0]\n",
      " [ 8  0  0  0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  8  2  0]\n",
      " [16  2  0  0]\n",
      " [64  0  0  0]\n",
      " [ 8  0  0  0]]\n",
      "Q:  tensor([[0.3435, 0.1310, 0.3211, 0.0653]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  2  0  0]\n",
      " [16  0  0  0]\n",
      " [64  8  0  0]\n",
      " [ 8  2  2  0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  2  0  0]\n",
      " [16  0  0  0]\n",
      " [64  8  0  0]\n",
      " [ 8  2  2  0]]\n",
      "Q:  tensor([[0.5530, 0.2714, 0.6812, 0.5423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  4]\n",
      " [ 0  0  0 16]\n",
      " [ 0  2 64  8]\n",
      " [ 0  0  8  4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  4]\n",
      " [ 0  0  0 16]\n",
      " [ 0  2 64  8]\n",
      " [ 0  0  8  4]]\n",
      "Q:  tensor([[ 0.1773,  0.2487, -0.0370,  0.2184]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2 64  4]\n",
      " [ 0  0  8 16]\n",
      " [ 0  0  0  8]\n",
      " [ 2  0  0  4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2 64  4]\n",
      " [ 0  0  8 16]\n",
      " [ 0  0  0  8]\n",
      " [ 2  0  0  4]]\n",
      "Q:  tensor([[0.4344, 0.2171, 0.3295, 0.2015]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  4]\n",
      " [ 0  0  0 16]\n",
      " [ 0  2 64  8]\n",
      " [ 2  2  8  4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  4]\n",
      " [ 0  0  0 16]\n",
      " [ 0  2 64  8]\n",
      " [ 2  2  8  4]]\n",
      "Q:  tensor([[0.7248, 0.7423, 0.8234, 0.7776]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  2  4]\n",
      " [ 0  0  0 16]\n",
      " [ 0  2 64  8]\n",
      " [ 0  4  8  4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  2  4]\n",
      " [ 0  0  0 16]\n",
      " [ 0  2 64  8]\n",
      " [ 0  4  8  4]]\n",
      "Q:  tensor([[ 0.0393,  0.4406, -0.0339,  0.3055]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  2  2  4]\n",
      " [ 0  4 64 16]\n",
      " [ 0  0  8  8]\n",
      " [ 0  0  0  4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  2  2  4]\n",
      " [ 0  4 64 16]\n",
      " [ 0  0  8  8]\n",
      " [ 0  0  0  4]]\n",
      "Q:  tensor([[0.4283, 0.3827, 0.8712, 0.9037]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 4  2  4  0]\n",
      " [ 4 64 16  0]\n",
      " [16  0  0  0]\n",
      " [ 4  0  2  0]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 4  2  4  0]\n",
      " [ 4 64 16  0]\n",
      " [16  0  0  0]\n",
      " [ 4  0  2  0]]\n",
      "Q:  tensor([[0.7323, 0.7450, 0.1782, 0.3368]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8  2  4  0]\n",
      " [16 64 16  2]\n",
      " [ 4  0  2  0]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8  2  4  0]\n",
      " [16 64 16  2]\n",
      " [ 4  0  2  0]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[0.4301, 0.3723, 0.3200, 0.4824]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8  2  4  0]\n",
      " [16 64 16  2]\n",
      " [ 4  2  0  2]\n",
      " [ 0  0  0  0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8  2  4  0]\n",
      " [16 64 16  2]\n",
      " [ 4  2  0  2]\n",
      " [ 0  0  0  0]]\n",
      "Q:  tensor([[0.8305, 0.7542, 0.8518, 0.8434]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  8  2  4]\n",
      " [16 64 16  2]\n",
      " [ 0  0  4  4]\n",
      " [ 0  0  0  4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  8  2  4]\n",
      " [16 64 16  2]\n",
      " [ 0  0  4  4]\n",
      " [ 0  0  0  4]]\n",
      "Q:  tensor([[0.8376, 0.6741, 0.7727, 0.8466]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8  2  4  0]\n",
      " [16 64 16  2]\n",
      " [ 8  2  0  0]\n",
      " [ 4  0  0  0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8  2  4  0]\n",
      " [16 64 16  2]\n",
      " [ 8  2  0  0]\n",
      " [ 4  0  0  0]]\n",
      "Q:  tensor([[ 0.4424,  0.0086,  0.2323, -0.4000]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8  0  0  0]\n",
      " [16  2  0  0]\n",
      " [ 8 64  4  2]\n",
      " [ 4  2 16  2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8  0  0  0]\n",
      " [16  2  0  0]\n",
      " [ 8 64  4  2]\n",
      " [ 4  2 16  2]]\n",
      "Q:  tensor([[ 0.8541,  0.9135,  0.2655, -0.0439]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8  2  4  4]\n",
      " [16 64 16  0]\n",
      " [ 8  2  2  0]\n",
      " [ 4  0  0  0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8  2  4  4]\n",
      " [16 64 16  0]\n",
      " [ 8  2  2  0]\n",
      " [ 4  0  0  0]]\n",
      "Q:  tensor([[0.2944, 0.0941, 0.6382, 0.8756]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8  2  8  0]\n",
      " [16 64 16  0]\n",
      " [ 8  4  0  0]\n",
      " [ 4  0  2  0]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8  2  8  0]\n",
      " [16 64 16  0]\n",
      " [ 8  4  0  0]\n",
      " [ 4  0  2  0]]\n",
      "Q:  tensor([[0.2892, 0.1585, 0.1876, 0.3203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 8  2  8  0]\n",
      " [16 64 16  0]\n",
      " [ 8  4  0  0]\n",
      " [ 4  2  0  2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 8  2  8  0]\n",
      " [16 64 16  0]\n",
      " [ 8  4  0  0]\n",
      " [ 4  2  0  2]]\n",
      "Q:  tensor([[0.3600, 0.2380, 0.8852, 0.8333]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  8  2  8]\n",
      " [ 0 16 64 16]\n",
      " [ 0  0  8  4]\n",
      " [ 0  4  4  4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  8  2  8]\n",
      " [ 0 16 64 16]\n",
      " [ 0  0  8  4]\n",
      " [ 0  4  4  4]]\n",
      "Q:  tensor([[0.8768, 0.6997, 0.7262, 0.6320]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2  2  0]\n",
      " [ 0  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  4  4  8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2  2  0]\n",
      " [ 0  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  4  4  8]]\n",
      "Q:  tensor([[0.0616, 0.2729, 0.8754, 0.7747]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  0  0  4]\n",
      " [ 0  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  0  8  8]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  0  0  4]\n",
      " [ 0  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  0  8  8]]\n",
      "Q:  tensor([[0.8317, 0.7667, 0.9801, 0.6480]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2  2  4]\n",
      " [ 0  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  0  0 16]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2  2  4]\n",
      " [ 0  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  0  0 16]]\n",
      "Q:  tensor([[0.5868, 0.5826, 0.8905, 0.8370]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2  4  4]\n",
      " [ 0  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  0  0 16]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2  4  4]\n",
      " [ 0  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  0  0 16]]\n",
      "Q:  tensor([[0.7260, 0.5884, 0.8970, 0.5945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  2  8]\n",
      " [ 2  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  0  0 16]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  2  8]\n",
      " [ 2  8 64  8]\n",
      " [ 0 16  8 16]\n",
      " [ 0  0  0 16]]\n",
      "Q:  tensor([[0.7024, 0.8432, 0.0528, 0.2634]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  8  2 16]\n",
      " [ 0 16 64 32]\n",
      " [ 0  0  8 16]\n",
      " [ 0  0  2  0]]\n",
      "Reward: 48 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  8  2 16]\n",
      " [ 0 16 64 32]\n",
      " [ 0  0  8 16]\n",
      " [ 0  0  2  0]]\n",
      "Q:  tensor([[ 0.3209, -0.2980,  0.0930,  0.3088]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  0  2  0]\n",
      " [ 0  0 64 16]\n",
      " [ 0  8  8 32]\n",
      " [ 2 16  2 16]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  0  2  0]\n",
      " [ 0  0 64 16]\n",
      " [ 0  8  8 32]\n",
      " [ 2 16  2 16]]\n",
      "Q:  tensor([[0.8405, 0.6368, 0.6727, 0.6433]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  2  2  0]\n",
      " [ 0  0 64 16]\n",
      " [ 0  8  8 32]\n",
      " [ 4 16  2 16]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  2  2  0]\n",
      " [ 0  0 64 16]\n",
      " [ 0  8  8 32]\n",
      " [ 4 16  2 16]]\n",
      "Q:  tensor([[0.2435, 0.3669, 0.6880, 0.7833]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 4  0  0  4]\n",
      " [64 16  0  0]\n",
      " [16 32  0  0]\n",
      " [ 4 16  2 16]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 4  0  0  4]\n",
      " [64 16  0  0]\n",
      " [16 32  0  0]\n",
      " [ 4 16  2 16]]\n",
      "Q:  tensor([[0.3346, 0.4837, 0.6657, 0.6129]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2  0  0  8]\n",
      " [ 0  0 64 16]\n",
      " [ 0  0 16 32]\n",
      " [ 4 16  2 16]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2  0  0  8]\n",
      " [ 0  0 64 16]\n",
      " [ 0  0 16 32]\n",
      " [ 4 16  2 16]]\n",
      "Q:  tensor([[0.1819, 0.4338, 0.1486, 0.2739]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2 16 64  8]\n",
      " [ 4  0 16 16]\n",
      " [ 0  2  2 32]\n",
      " [ 0  0  0 16]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2 16 64  8]\n",
      " [ 4  0 16 16]\n",
      " [ 0  2  2 32]\n",
      " [ 0  0  0 16]]\n",
      "Q:  tensor([[0.5384, 0.3696, 0.9765, 0.8663]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 2 16 64  8]\n",
      " [ 0  0  4 32]\n",
      " [ 0  0  4 32]\n",
      " [ 0  2  0 16]]\n",
      "Reward: 36 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 2 16 64  8]\n",
      " [ 0  0  4 32]\n",
      " [ 0  0  4 32]\n",
      " [ 0  2  0 16]]\n",
      "Q:  tensor([[0.7480, 0.7420, 0.5178, 0.3727]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 0  0  0  0]\n",
      " [ 2  0  0  8]\n",
      " [ 0 16 64 64]\n",
      " [ 2  2  8 16]]\n",
      "Reward: 72 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 0  0  0  0]\n",
      " [ 2  0  0  8]\n",
      " [ 0 16 64 64]\n",
      " [ 2  2  8 16]]\n",
      "Q:  tensor([[0.6509, 0.5647, 0.8122, 0.7151]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0   0]\n",
      " [  0   0   2   8]\n",
      " [  0   0  16 128]\n",
      " [  0   4   8  16]]\n",
      "Reward: 132 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0   0]\n",
      " [  0   0   2   8]\n",
      " [  0   0  16 128]\n",
      " [  0   4   8  16]]\n",
      "Q:  tensor([[0.2941, 0.5396, 0.2731, 0.4368]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   2   8]\n",
      " [  0   4  16 128]\n",
      " [  0   0   8  16]\n",
      " [  0   0   0   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   2   8]\n",
      " [  0   4  16 128]\n",
      " [  0   0   8  16]\n",
      " [  0   0   0   2]]\n",
      "Q:  tensor([[0.3301, 0.3803, 0.7363, 0.9571]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8   0   0]\n",
      " [  4  16 128   0]\n",
      " [  8  16   0   0]\n",
      " [  2   0   0   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8   0   0]\n",
      " [  4  16 128   0]\n",
      " [  8  16   0   0]\n",
      " [  2   0   0   2]]\n",
      "Q:  tensor([[0.8534, 0.8426, 0.5326, 0.9202]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8   0   0]\n",
      " [  4  16 128   2]\n",
      " [  8  16   0   0]\n",
      " [  4   0   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8   0   0]\n",
      " [  4  16 128   2]\n",
      " [  8  16   0   0]\n",
      " [  4   0   0   0]]\n",
      "Q:  tensor([[0.7671, 0.8592, 0.3223, 0.3982]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   8 128   2]\n",
      " [  8  32   0   0]\n",
      " [  4   0   0   0]\n",
      " [  2   0   0   0]]\n",
      "Reward: 40 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   8 128   2]\n",
      " [  8  32   0   0]\n",
      " [  4   0   0   0]\n",
      " [  2   0   0   0]]\n",
      "Q:  tensor([[0.6991, 0.7884, 0.8916, 0.7791]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0  16 128   2]\n",
      " [  0   2   8  32]\n",
      " [  0   0   0   4]\n",
      " [  0   0   0   2]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0  16 128   2]\n",
      " [  0   2   8  32]\n",
      " [  0   0   0   4]\n",
      " [  0   0   0   2]]\n",
      "Q:  tensor([[ 0.1269, -0.0966, -0.3680,  0.3590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16 128   2   0]\n",
      " [  2   8  32   0]\n",
      " [  4   0   4   0]\n",
      " [  2   0   0   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16 128   2   0]\n",
      " [  2   8  32   0]\n",
      " [  4   0   4   0]\n",
      " [  2   0   0   0]]\n",
      "Q:  tensor([[0.3364, 0.1598, 0.9279, 0.8357]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0  16 128   2]\n",
      " [  0   2   8  32]\n",
      " [  0   0   0   8]\n",
      " [  0   0   2   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0  16 128   2]\n",
      " [  0   2   8  32]\n",
      " [  0   0   0   8]\n",
      " [  0   0   2   2]]\n",
      "Q:  tensor([[0.3857, 0.1613, 0.4337, 0.7334]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16 128   2   0]\n",
      " [  2   8  32   0]\n",
      " [  8   0   0   0]\n",
      " [  4   2   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16 128   2   0]\n",
      " [  2   8  32   0]\n",
      " [  8   0   0   0]\n",
      " [  4   2   0   0]]\n",
      "Q:  tensor([[ 0.3880,  0.0780,  0.3288, -0.2845]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   0   0   0]\n",
      " [  2 128   0   0]\n",
      " [  8   8   2   2]\n",
      " [  4   2  32   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   0   0   0]\n",
      " [  2 128   0   0]\n",
      " [  8   8   2   2]\n",
      " [  4   2  32   0]]\n",
      "Q:  tensor([[0.3324, 0.3260, 0.7350, 0.7173]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0  16]\n",
      " [  0   0   2 128]\n",
      " [  0   8  16   4]\n",
      " [  0   4   2  32]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0  16]\n",
      " [  0   0   2 128]\n",
      " [  0   8  16   4]\n",
      " [  0   4   2  32]]\n",
      "Q:  tensor([[0.2488, 0.2899, 0.1744, 0.3389]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16   2   0]\n",
      " [  2 128   0   0]\n",
      " [  8  16   4   0]\n",
      " [  4   2  32   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16   2   0]\n",
      " [  2 128   0   0]\n",
      " [  8  16   4   0]\n",
      " [  4   2  32   0]]\n",
      "Q:  tensor([[0.7826, 0.8278, 0.4480, 0.3237]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16   2   2]\n",
      " [  8 128   4   0]\n",
      " [  4  16  32   0]\n",
      " [  0   2   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16   2   2]\n",
      " [  8 128   4   0]\n",
      " [  4  16  32   0]\n",
      " [  0   2   0   0]]\n",
      "Q:  tensor([[0.3884, 0.0608, 0.9082, 0.9584]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16   4   0]\n",
      " [  8 128   4   0]\n",
      " [  4  16  32   0]\n",
      " [  2   0   2   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16   4   0]\n",
      " [  8 128   4   0]\n",
      " [  4  16  32   0]\n",
      " [  2   0   2   0]]\n",
      "Q:  tensor([[0.7651, 0.8295, 0.7501, 0.9496]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16   4   0]\n",
      " [  8 128   4   0]\n",
      " [  4  16  32   0]\n",
      " [  4   0   2   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16   4   0]\n",
      " [  8 128   4   0]\n",
      " [  4  16  32   0]\n",
      " [  4   0   2   0]]\n",
      "Q:  tensor([[0.7979, 0.7801, 0.3880, 0.3140]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [  4  16   8   0]\n",
      " [  8 128  32   0]\n",
      " [  8  16   2   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [  4  16   8   0]\n",
      " [  8 128  32   0]\n",
      " [  8  16   2   0]]\n",
      "Q:  tensor([[ 0.7055,  0.6872,  0.3411, -0.0101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   0]\n",
      " [  2  16   8   0]\n",
      " [  4 128  32   2]\n",
      " [ 16  16   2   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   0]\n",
      " [  2  16   8   0]\n",
      " [  4 128  32   2]\n",
      " [ 16  16   2   0]]\n",
      "Q:  tensor([[0.4894, 0.5744, 0.8054, 0.7988]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2   0]\n",
      " [  0   2  16   8]\n",
      " [  4 128  32   2]\n",
      " [  0   0  32   2]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2   0]\n",
      " [  0   2  16   8]\n",
      " [  4 128  32   2]\n",
      " [  0   0  32   2]]\n",
      "Q:  tensor([[0.8179, 0.9182, 0.0865, 0.5740]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2   2   8]\n",
      " [  0 128  16   4]\n",
      " [  0   0  64   0]\n",
      " [  0   0   2   0]]\n",
      "Reward: 68 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2   2   8]\n",
      " [  0 128  16   4]\n",
      " [  0   0  64   0]\n",
      " [  0   0   2   0]]\n",
      "Q:  tensor([[0.2876, 0.1390, 0.8038, 0.9494]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4   8   0]\n",
      " [128  16   4   0]\n",
      " [ 64   0   0   0]\n",
      " [  2   0   2   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4   8   0]\n",
      " [128  16   4   0]\n",
      " [ 64   0   0   0]\n",
      " [  2   0   2   0]]\n",
      "Q:  tensor([[0.1454, 0.3766, 0.7375, 0.8757]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   8   0   2]\n",
      " [128  16   4   0]\n",
      " [ 64   0   0   0]\n",
      " [  4   0   0   0]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   8   0   2]\n",
      " [128  16   4   0]\n",
      " [ 64   0   0   0]\n",
      " [  4   0   0   0]]\n",
      "Q:  tensor([[0.4273, 0.3782, 0.7584, 0.8444]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   2   2   0]\n",
      " [128  16   4   0]\n",
      " [ 64   0   0   0]\n",
      " [  4   0   0   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   2   2   0]\n",
      " [128  16   4   0]\n",
      " [ 64   0   0   0]\n",
      " [  4   0   0   0]]\n",
      "Q:  tensor([[0.2602, 0.2401, 0.8996, 0.7181]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0  16   4]\n",
      " [  0 128  16   4]\n",
      " [  0   0   2  64]\n",
      " [  0   0   0   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0  16   4]\n",
      " [  0 128  16   4]\n",
      " [  0   0   2  64]\n",
      " [  0   0   0   4]]\n",
      "Q:  tensor([[0.6619, 0.8262, 0.3268, 0.0650]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0 128  32   8]\n",
      " [  0   2   2  64]\n",
      " [  0   0   0   4]\n",
      " [  0   0   0   0]]\n",
      "Reward: 40 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0 128  32   8]\n",
      " [  0   2   2  64]\n",
      " [  0   0   0   4]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[ 0.3891, -0.0575,  0.4105,  0.9149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[128  32   8   0]\n",
      " [  4  64   0   0]\n",
      " [  4   0   0   0]\n",
      " [  0   0   2   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[128  32   8   0]\n",
      " [  4  64   0   0]\n",
      " [  4   0   0   0]\n",
      " [  0   0   2   0]]\n",
      "Q:  tensor([[ 0.5125,  0.6860,  0.1585, -0.0263]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[128  32   8   2]\n",
      " [  8  64   2   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[128  32   8   2]\n",
      " [  8  64   2   0]\n",
      " [  0   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[0.2857, 0.0753, 0.3962, 0.2305]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[128  32   8   2]\n",
      " [  0   8  64   2]\n",
      " [  0   0   0   0]\n",
      " [  0   0   2   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[128  32   8   2]\n",
      " [  0   8  64   2]\n",
      " [  0   0   0   0]\n",
      " [  0   0   2   0]]\n",
      "Q:  tensor([[0.8242, 0.8148, 0.1396, 0.5050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   0]\n",
      " [  0   0   8   0]\n",
      " [  4  32  64   0]\n",
      " [128   8   2   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   0]\n",
      " [  0   0   8   0]\n",
      " [  4  32  64   0]\n",
      " [128   8   2   4]]\n",
      "Q:  tensor([[-0.3772,  0.2724,  0.1928,  0.0050]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   8   4]\n",
      " [128   8  64   0]\n",
      " [  2   0   2   0]\n",
      " [  0   0   0   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   8   4]\n",
      " [128   8  64   0]\n",
      " [  2   0   2   0]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[0.3565, 0.0659, 0.8116, 0.5719]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   8   4]\n",
      " [  0 128   8  64]\n",
      " [  4   0   0   4]\n",
      " [  0   0   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   8   4]\n",
      " [  0 128   8  64]\n",
      " [  4   0   0   4]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[0.6762, 0.7904, 0.7653, 0.7466]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8  32  16   4]\n",
      " [  0 128   0  64]\n",
      " [  0   0   0   4]\n",
      " [  0   0   2   0]]\n",
      "Reward: 24 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8  32  16   4]\n",
      " [  0 128   0  64]\n",
      " [  0   0   0   4]\n",
      " [  0   0   2   0]]\n",
      "Q:  tensor([[0.1408, 0.2488, 0.1800, 0.2546]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8  32  16   4]\n",
      " [128  64   0   0]\n",
      " [  4   0   0   2]\n",
      " [  2   0   0   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8  32  16   4]\n",
      " [128  64   0   0]\n",
      " [  4   0   0   2]\n",
      " [  2   0   0   0]]\n",
      "Q:  tensor([[ 0.0856, -0.1922,  0.4327,  0.3680]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8  32  16   4]\n",
      " [  0   0 128  64]\n",
      " [  0   2   4   2]\n",
      " [  0   0   0   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8  32  16   4]\n",
      " [  0   0 128  64]\n",
      " [  0   2   4   2]\n",
      " [  0   0   0   2]]\n",
      "Q:  tensor([[0.8325, 0.8158, 0.2824, 0.3584]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  0   0  16   4]\n",
      " [  0  32 128  64]\n",
      " [  8   2   4   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  0   0  16   4]\n",
      " [  0  32 128  64]\n",
      " [  8   2   4   4]]\n",
      "Q:  tensor([[-0.1678,  0.3194,  0.7958,  0.6162]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   2]\n",
      " [  0   0  16   4]\n",
      " [  0  32 128  64]\n",
      " [  0   8   2   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   2]\n",
      " [  0   0  16   4]\n",
      " [  0  32 128  64]\n",
      " [  0   8   2   8]]\n",
      "Q:  tensor([[0.1588, 0.2376, 0.7823, 0.7180]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   4]\n",
      " [  0   0  16   4]\n",
      " [  0  32 128  64]\n",
      " [  4   8   2   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   4]\n",
      " [  0   0  16   4]\n",
      " [  0  32 128  64]\n",
      " [  4   8   2   8]]\n",
      "Q:  tensor([[ 0.6673,  0.5709, -0.1393,  0.0886]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  0   0  16   8]\n",
      " [  0  32 128  64]\n",
      " [  4   8   2   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  0   0  16   8]\n",
      " [  0  32 128  64]\n",
      " [  4   8   2   8]]\n",
      "Q:  tensor([[-0.4788, -0.0092, -0.3095,  0.3426]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [ 16   8   0   0]\n",
      " [ 32 128  64   2]\n",
      " [  4   8   2   8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [ 16   8   0   0]\n",
      " [ 32 128  64   2]\n",
      " [  4   8   2   8]]\n",
      "Q:  tensor([[-0.3230,  0.2661,  0.2545, -0.1902]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8  64   2]\n",
      " [ 16 128   2   8]\n",
      " [ 32   8   0   0]\n",
      " [  4   0   0   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   8  64   2]\n",
      " [ 16 128   2   8]\n",
      " [ 32   8   0   0]\n",
      " [  4   0   0   2]]\n",
      "Q:  tensor([[0.4758, 0.2737, 0.3354, 0.3289]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   2   0]\n",
      " [ 16   8   0   2]\n",
      " [ 32 128  64   8]\n",
      " [  4   8   2   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   2   0]\n",
      " [ 16   8   0   2]\n",
      " [ 32 128  64   8]\n",
      " [  4   8   2   2]]\n",
      "Q:  tensor([[0.4010, 0.4222, 0.5974, 0.6635]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2   0   0]\n",
      " [ 16   8   2   0]\n",
      " [ 32 128  64   8]\n",
      " [  4   8   4   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2   0   0]\n",
      " [ 16   8   2   0]\n",
      " [ 32 128  64   8]\n",
      " [  4   8   4   0]]\n",
      "Q:  tensor([[ 0.2144,  0.3147,  0.3947, -0.1925]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   4   4   2]\n",
      " [  0  16   8   2]\n",
      " [ 32 128  64   8]\n",
      " [  0   4   8   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   4   4   2]\n",
      " [  0  16   8   2]\n",
      " [ 32 128  64   8]\n",
      " [  0   4   8   4]]\n",
      "Q:  tensor([[0.8894, 0.7991, 0.7206, 0.8131]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   4   4   0]\n",
      " [  0  16   8   4]\n",
      " [  4 128  64   8]\n",
      " [ 32   4   8   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   4   4   0]\n",
      " [  0  16   8   4]\n",
      " [  4 128  64   8]\n",
      " [ 32   4   8   4]]\n",
      "Q:  tensor([[0.0742, 0.4363, 0.8613, 0.8275]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2   8]\n",
      " [  0  16   8   4]\n",
      " [  4 128  64   8]\n",
      " [ 32   4   8   4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2   8]\n",
      " [  0  16   8   4]\n",
      " [  4 128  64   8]\n",
      " [ 32   4   8   4]]\n",
      "Q:  tensor([[ 0.0942,  0.3077, -0.2327,  0.3725]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8   0   2]\n",
      " [ 16   8   4   0]\n",
      " [  4 128  64   8]\n",
      " [ 32   4   8   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   8   0   2]\n",
      " [ 16   8   4   0]\n",
      " [  4 128  64   8]\n",
      " [ 32   4   8   4]]\n",
      "Q:  tensor([[0.6981, 0.9202, 0.3192, 0.3489]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16   4   2]\n",
      " [ 16 128  64   8]\n",
      " [  4   4   8   4]\n",
      " [ 32   0   0   2]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16   4   2]\n",
      " [ 16 128  64   8]\n",
      " [  4   4   8   4]\n",
      " [ 32   0   0   2]]\n",
      "Q:  tensor([[ 0.4112, -0.0059,  0.8942,  0.8826]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16   4   2]\n",
      " [ 16 128  64   8]\n",
      " [  2   8   8   4]\n",
      " [  0   0  32   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16   4   2]\n",
      " [ 16 128  64   8]\n",
      " [  2   8   8   4]\n",
      " [  0   0  32   2]]\n",
      "Q:  tensor([[ 0.4170, -0.0678,  0.9001,  0.8607]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16   4   2]\n",
      " [ 16 128  64   8]\n",
      " [  0   2  16   4]\n",
      " [  2   0  32   2]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16   4   2]\n",
      " [ 16 128  64   8]\n",
      " [  0   2  16   4]\n",
      " [  2   0  32   2]]\n",
      "Q:  tensor([[0.5784, 0.3873, 0.4925, 0.4142]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   4   2]\n",
      " [  2  16  64   8]\n",
      " [ 16 128  16   4]\n",
      " [  2   2  32   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   4   2]\n",
      " [  2  16  64   8]\n",
      " [ 16 128  16   4]\n",
      " [  2   2  32   2]]\n",
      "Q:  tensor([[0.4026, 0.5563, 0.8963, 0.8734]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   4   2]\n",
      " [  2  16  64   8]\n",
      " [ 16 128  16   4]\n",
      " [  2   4  32   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   4   2]\n",
      " [  2  16  64   8]\n",
      " [ 16 128  16   4]\n",
      " [  2   4  32   2]]\n",
      "Q:  tensor([[-0.1496,  0.4519,  0.1420,  0.4090]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   4   2]\n",
      " [ 16  16  64   8]\n",
      " [  2 128  16   4]\n",
      " [  2   4  32   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   4   2]\n",
      " [ 16  16  64   8]\n",
      " [  2 128  16   4]\n",
      " [  2   4  32   2]]\n",
      "Q:  tensor([[0.7742, 0.8318, 0.9078, 0.8660]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   4   4   2]\n",
      " [  2  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  2   4  32   2]]\n",
      "Reward: 36 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   4   4   2]\n",
      " [  2  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  2   4  32   2]]\n",
      "Q:  tensor([[0.9071, 0.9424, 0.8760, 1.0052]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2   0   2]\n",
      " [  2  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  2   4  32   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2   0   2]\n",
      " [  2  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  2   4  32   2]]\n",
      "Q:  tensor([[0.9752, 0.9065, 0.7981, 0.9327]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   2   2]\n",
      " [  8  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  4   4  32   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   2   2]\n",
      " [  8  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  4   4  32   2]]\n",
      "Q:  tensor([[0.1075, 0.3474, 0.6340, 0.9794]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2   0   2]\n",
      " [  8  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  8  32   2   0]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2   0   2]\n",
      " [  8  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  8  32   2   0]]\n",
      "Q:  tensor([[0.2003, 0.2000, 1.0257, 0.8423]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   4   4]\n",
      " [  8  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  0   8  32   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   4   4]\n",
      " [  8  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  0   8  32   2]]\n",
      "Q:  tensor([[0.3188, 0.3323, 0.8994, 0.7639]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   2   8]\n",
      " [  8  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  0   8  32   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   2   8]\n",
      " [  8  32  64   8]\n",
      " [  2 128  16   4]\n",
      " [  0   8  32   2]]\n",
      "Q:  tensor([[0.7817, 0.9229, 0.2620, 0.2961]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   2  16]\n",
      " [  8 128  64   4]\n",
      " [  2   8  16   2]\n",
      " [  2   0  32   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   2  16]\n",
      " [  8 128  64   4]\n",
      " [  2   8  16   2]\n",
      " [  2   0  32   0]]\n",
      "Q:  tensor([[0.9406, 0.6709, 0.3355, 0.3875]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   2   0]\n",
      " [  4  32  64  16]\n",
      " [  8 128  16   4]\n",
      " [  4   8  32   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   2   0]\n",
      " [  4  32  64  16]\n",
      " [  8 128  16   4]\n",
      " [  4   8  32   2]]\n",
      "Q:  tensor([[0.1549, 0.4143, 0.8470, 0.7864]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0   4]\n",
      " [  4  32  64  16]\n",
      " [  8 128  16   4]\n",
      " [  4   8  32   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0   4]\n",
      " [  4  32  64  16]\n",
      " [  8 128  16   4]\n",
      " [  4   8  32   2]]\n",
      "Q:  tensor([[-0.2297,  0.3410,  0.2759,  0.1059]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2  64   4]\n",
      " [  8  32  16  16]\n",
      " [  4 128  32   4]\n",
      " [  0   8   2   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2  64   4]\n",
      " [  8  32  16  16]\n",
      " [  4 128  32   4]\n",
      " [  0   8   2   2]]\n",
      "Q:  tensor([[0.3304, 0.2958, 0.9615, 0.6587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2  64   4]\n",
      " [  0   8  32  32]\n",
      " [  4 128  32   4]\n",
      " [  0   2   8   4]]\n",
      "Reward: 36 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2  64   4]\n",
      " [  0   8  32  32]\n",
      " [  4 128  32   4]\n",
      " [  0   2   8   4]]\n",
      "Q:  tensor([[0.9260, 0.7688, 0.8844, 0.8386]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   0   0]\n",
      " [  0   8  64   4]\n",
      " [  0 128  64  32]\n",
      " [  8   2   8   8]]\n",
      "Reward: 80 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   0   0]\n",
      " [  0   8  64   4]\n",
      " [  0 128  64  32]\n",
      " [  8   2   8   8]]\n",
      "Q:  tensor([[0.6909, 0.6738, 0.8899, 0.6647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   4]\n",
      " [  0   8  64   4]\n",
      " [  4 128  64  32]\n",
      " [  0   8   2  16]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   4]\n",
      " [  0   8  64   4]\n",
      " [  4 128  64  32]\n",
      " [  0   8   2  16]]\n",
      "Q:  tensor([[0.6010, 0.7334, 0.2485, 0.3202]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8 128   8]\n",
      " [  2 128   2  32]\n",
      " [  0   8   0  16]\n",
      " [  0   0   0   0]]\n",
      "Reward: 136 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8 128   8]\n",
      " [  2 128   2  32]\n",
      " [  0   8   0  16]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[ 0.2638, -0.1084,  0.1056,  0.1876]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0   0]\n",
      " [  0   8   0   8]\n",
      " [  4 128 128  32]\n",
      " [  2   8   2  16]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0   0]\n",
      " [  0   8   0   8]\n",
      " [  4 128 128  32]\n",
      " [  2   8   2  16]]\n",
      "Q:  tensor([[0.0238, 0.5857, 0.2168, 0.4235]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2 128   8]\n",
      " [  2   8   2  32]\n",
      " [  0 128   2  16]\n",
      " [  0   8   0   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2 128   8]\n",
      " [  2   8   2  32]\n",
      " [  0 128   2  16]\n",
      " [  0   8   0   0]]\n",
      "Q:  tensor([[0.6255, 0.8121, 0.3163, 0.1416]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2 128   8]\n",
      " [  2   8   4  32]\n",
      " [  0 128   0  16]\n",
      " [  0   8   0   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2 128   8]\n",
      " [  2   8   4  32]\n",
      " [  0 128   0  16]\n",
      " [  0   8   0   2]]\n",
      "Q:  tensor([[ 0.2940, -0.1081, -0.1846,  0.3306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2 128   8]\n",
      " [  2   8   4  32]\n",
      " [128  16   0   2]\n",
      " [  8   2   0   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2 128   8]\n",
      " [  2   8   4  32]\n",
      " [128  16   0   2]\n",
      " [  8   2   0   0]]\n",
      "Q:  tensor([[ 0.3565, -0.0958,  0.5215,  0.3602]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2 128   8]\n",
      " [  2   8   4  32]\n",
      " [  2 128  16   2]\n",
      " [  0   0   8   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2 128   8]\n",
      " [  2   8   4  32]\n",
      " [  2 128  16   2]\n",
      " [  0   0   8   2]]\n",
      "Q:  tensor([[0.9387, 0.7668, 0.3003, 0.3349]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2 128   0]\n",
      " [  0   2   4   8]\n",
      " [  4   8  16  32]\n",
      " [  4 128   8   4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2 128   0]\n",
      " [  0   2   4   8]\n",
      " [  4   8  16  32]\n",
      " [  4 128   8   4]]\n",
      "Q:  tensor([[0.7919, 0.7883, 0.3675, 0.3280]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2 128   0]\n",
      " [  0   4   4   8]\n",
      " [  0   8  16  32]\n",
      " [  8 128   8   4]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2 128   0]\n",
      " [  0   4   4   8]\n",
      " [  0   8  16  32]\n",
      " [  8 128   8   4]]\n",
      "Q:  tensor([[0.0156, 0.0175, 0.8555, 0.7706]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   2 128]\n",
      " [  0   0   8   8]\n",
      " [  0   8  16  32]\n",
      " [  8 128   8   4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   2 128]\n",
      " [  0   0   8   8]\n",
      " [  0   8  16  32]\n",
      " [  8 128   8   4]]\n",
      "Q:  tensor([[0.1403, 0.0500, 0.8334, 0.6128]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   4 128]\n",
      " [  0   0   0  16]\n",
      " [  0   8  16  32]\n",
      " [  8 128   8   4]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   4 128]\n",
      " [  0   0   0  16]\n",
      " [  0   8  16  32]\n",
      " [  8 128   8   4]]\n",
      "Q:  tensor([[ 0.2096,  0.2345, -0.0724,  0.3330]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 128   0]\n",
      " [ 16   0   2   0]\n",
      " [  8  16  32   0]\n",
      " [  8 128   8   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 128   0]\n",
      " [ 16   0   2   0]\n",
      " [  8  16  32   0]\n",
      " [  8 128   8   4]]\n",
      "Q:  tensor([[0.8899, 0.6993, 0.3180, 0.2839]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0 128   0]\n",
      " [  2   4   2   0]\n",
      " [ 16  16  32   2]\n",
      " [ 16 128   8   4]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0 128   0]\n",
      " [  2   4   2   0]\n",
      " [ 16  16  32   2]\n",
      " [ 16 128   8   4]]\n",
      "Q:  tensor([[0.7391, 0.7560, 0.7209, 0.9450]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[128   0   0   0]\n",
      " [  2   4   2   0]\n",
      " [ 32  32   2   2]\n",
      " [ 16 128   8   4]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[128   0   0   0]\n",
      " [  2   4   2   0]\n",
      " [ 32  32   2   2]\n",
      " [ 16 128   8   4]]\n",
      "Q:  tensor([[0.7312, 0.7407, 0.9644, 0.9019]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2 128]\n",
      " [  0   2   4   2]\n",
      " [  0  32  64   4]\n",
      " [ 16 128   8   4]]\n",
      "Reward: 68 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2 128]\n",
      " [  0   2   4   2]\n",
      " [  0  32  64   4]\n",
      " [ 16 128   8   4]]\n",
      "Q:  tensor([[0.8605, 0.8527, 0.0739, 0.5282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   2   0]\n",
      " [  0   2   4 128]\n",
      " [  0  32  64   2]\n",
      " [ 16 128   8   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   2   0]\n",
      " [  0   2   4 128]\n",
      " [  0  32  64   2]\n",
      " [ 16 128   8   8]]\n",
      "Q:  tensor([[0.8571, 0.8017, 0.7984, 0.7338]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2   2]\n",
      " [  0   4   4 128]\n",
      " [  0  32  64   2]\n",
      " [ 16 128   8   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2   2]\n",
      " [  0   4   4 128]\n",
      " [  0  32  64   2]\n",
      " [ 16 128   8   8]]\n",
      "Q:  tensor([[0.3983, 0.5520, 0.7118, 0.8098]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2   0   0]\n",
      " [  8 128   0   0]\n",
      " [ 32  64   2   0]\n",
      " [ 16 128  16   0]]\n",
      "Reward: 28 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2   0   0]\n",
      " [  8 128   0   0]\n",
      " [ 32  64   2   0]\n",
      " [ 16 128  16   0]]\n",
      "Q:  tensor([[ 0.1075,  0.3499,  0.3175, -0.0597]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2   2   0]\n",
      " [  8 128  16   0]\n",
      " [ 32  64   0   0]\n",
      " [ 16 128   0   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2   2   0]\n",
      " [  8 128  16   0]\n",
      " [ 32  64   0   0]\n",
      " [ 16 128   0   2]]\n",
      "Q:  tensor([[0.2619, 0.3496, 0.7880, 0.8452]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4   0   0]\n",
      " [  8 128  16   2]\n",
      " [ 32  64   0   0]\n",
      " [ 16 128   2   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4   0   0]\n",
      " [  8 128  16   2]\n",
      " [ 32  64   0   0]\n",
      " [ 16 128   2   0]]\n",
      "Q:  tensor([[0.4549, 0.4485, 0.5364, 0.7877]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2   0   0]\n",
      " [  8 128  16   2]\n",
      " [ 32  64   0   0]\n",
      " [ 16 128   2   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2   0   0]\n",
      " [  8 128  16   2]\n",
      " [ 32  64   0   0]\n",
      " [ 16 128   2   0]]\n",
      "Q:  tensor([[0.8936, 0.6680, 0.3599, 0.2030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0   0]\n",
      " [ 16 128   2   0]\n",
      " [ 32  64  16   0]\n",
      " [ 16 128   2   2]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0   0]\n",
      " [ 16 128   2   0]\n",
      " [ 32  64  16   0]\n",
      " [ 16 128   2   2]]\n",
      "Q:  tensor([[0.0802, 0.5020, 0.9281, 0.6865]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  0  16 128   2]\n",
      " [  0  32  64  16]\n",
      " [  2  16 128   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  0  16 128   2]\n",
      " [  0  32  64  16]\n",
      " [  2  16 128   4]]\n",
      "Q:  tensor([[ 0.6179,  0.6451, -0.2164,  0.3711]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16 128   4]\n",
      " [  0  32  64  16]\n",
      " [  0  16 128   4]\n",
      " [  0   2   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16 128   4]\n",
      " [  0  32  64  16]\n",
      " [  0  16 128   4]\n",
      " [  0   2   0   0]]\n",
      "Q:  tensor([[0.2588, 0.1152, 0.2245, 0.1127]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0  16   0   0]\n",
      " [  2  32 128   4]\n",
      " [  0  16  64  16]\n",
      " [  2   2 128   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0  16   0   0]\n",
      " [  2  32 128   4]\n",
      " [  0  16  64  16]\n",
      " [  2   2 128   4]]\n",
      "Q:  tensor([[0.6015, 0.6889, 0.8428, 0.6101]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0  16]\n",
      " [  2  32 128   4]\n",
      " [  0  16  64  16]\n",
      " [  0   4 128   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0  16]\n",
      " [  2  32 128   4]\n",
      " [  0  16  64  16]\n",
      " [  0   4 128   4]]\n",
      "Q:  tensor([[0.2432, 0.3339, 0.0881, 0.4415]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16   0   0]\n",
      " [  2  32 128   4]\n",
      " [ 16  64  16   0]\n",
      " [  4 128   4   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16   0   0]\n",
      " [  2  32 128   4]\n",
      " [ 16  64  16   0]\n",
      " [  4 128   4   2]]\n",
      "Q:  tensor([[ 0.6164,  0.7799,  0.4946, -0.0389]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16 128   4]\n",
      " [ 16  32  16   2]\n",
      " [  4  64   4   2]\n",
      " [  0 128   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16 128   4]\n",
      " [ 16  32  16   2]\n",
      " [  4  64   4   2]\n",
      " [  0 128   0   0]]\n",
      "Q:  tensor([[0.8767, 0.9242, 0.2892, 0.2391]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16 128   4]\n",
      " [ 16  32  16   4]\n",
      " [  4  64   4   0]\n",
      " [  0 128   0   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16 128   4]\n",
      " [ 16  32  16   4]\n",
      " [  4  64   4   0]\n",
      " [  0 128   0   2]]\n",
      "Q:  tensor([[0.7272, 0.8560, 0.4566, 0.5289]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16 128   8]\n",
      " [ 16  32  16   2]\n",
      " [  4  64   4   0]\n",
      " [  0 128   0   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16 128   8]\n",
      " [ 16  32  16   2]\n",
      " [  4  64   4   0]\n",
      " [  0 128   0   2]]\n",
      "Q:  tensor([[0.8260, 0.7862, 0.2046, 0.2539]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16   0   0]\n",
      " [  4  32 128   0]\n",
      " [ 16  64  16   8]\n",
      " [  4 128   4   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16   0   0]\n",
      " [  4  32 128   0]\n",
      " [ 16  64  16   8]\n",
      " [  4 128   4   4]]\n",
      "Q:  tensor([[0.1206, 0.1301, 0.8965, 0.3958]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   2  16]\n",
      " [  0   4  32 128]\n",
      " [ 16  64  16   8]\n",
      " [  0   4 128   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   2  16]\n",
      " [  0   4  32 128]\n",
      " [ 16  64  16   8]\n",
      " [  0   4 128   8]]\n",
      "Q:  tensor([[0.8600, 0.9323, 0.3409, 0.4032]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4   2  16]\n",
      " [ 16  64  32 128]\n",
      " [  2   4  16  16]\n",
      " [  0   0 128   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4   2  16]\n",
      " [ 16  64  32 128]\n",
      " [  2   4  16  16]\n",
      " [  0   0 128   0]]\n",
      "Q:  tensor([[0.4180, 0.3696, 0.8468, 0.8584]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2  16   0]\n",
      " [ 16  64  32 128]\n",
      " [  2   4  32   2]\n",
      " [128   0   0   0]]\n",
      "Reward: 40 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2  16   0]\n",
      " [ 16  64  32 128]\n",
      " [  2   4  32   2]\n",
      " [128   0   0   0]]\n",
      "Q:  tensor([[0.7526, 0.7161, 0.3466, 0.1566]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   0   0   2]\n",
      " [ 16   2   0   0]\n",
      " [  2  64  16 128]\n",
      " [128   4  64   2]]\n",
      "Reward: 64 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   0   0   2]\n",
      " [ 16   2   0   0]\n",
      " [  2  64  16 128]\n",
      " [128   4  64   2]]\n",
      "Q:  tensor([[0.0767, 0.5593, 0.3083, 0.2657]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2  16   2]\n",
      " [ 16  64  64 128]\n",
      " [  2   4   0   2]\n",
      " [128   0   2   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2  16   2]\n",
      " [ 16  64  64 128]\n",
      " [  2   4   0   2]\n",
      " [128   0   2   0]]\n",
      "Q:  tensor([[0.4529, 0.3816, 0.7709, 0.8993]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2  16   2]\n",
      " [ 16 128 128   2]\n",
      " [  2   4   2   0]\n",
      " [128   2   0   0]]\n",
      "Reward: 128 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2  16   2]\n",
      " [ 16 128 128   2]\n",
      " [  2   4   2   0]\n",
      " [128   2   0   0]]\n",
      "Q:  tensor([[0.8625, 0.7013, 0.5054, 0.1196]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2   0   0]\n",
      " [ 16 128  16   0]\n",
      " [  2   4 128   2]\n",
      " [128   2   2   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2   0   0]\n",
      " [ 16 128  16   0]\n",
      " [  2   4 128   2]\n",
      " [128   2   2   4]]\n",
      "Q:  tensor([[0.3585, 0.4461, 0.9153, 0.9306]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2   0   2]\n",
      " [ 16 128  16   0]\n",
      " [  2   4 128   2]\n",
      " [128   4   4   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2   0   2]\n",
      " [ 16 128  16   0]\n",
      " [  2   4 128   2]\n",
      " [128   4   4   0]]\n",
      "Q:  tensor([[0.8143, 0.7375, 0.7299, 0.7653]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   0   2   0]\n",
      " [ 16   2  16   0]\n",
      " [  2 128 128   0]\n",
      " [128   8   4   4]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   0   2   0]\n",
      " [ 16   2  16   0]\n",
      " [  2 128 128   0]\n",
      " [128   8   4   4]]\n",
      "Q:  tensor([[0.2741, 0.3347, 0.9773, 0.8326]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   8   2]\n",
      " [  0  16   2  16]\n",
      " [  0   0   2 256]\n",
      " [  0 128   8   8]]\n",
      "Reward: 264 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   8   2]\n",
      " [  0  16   2  16]\n",
      " [  0   0   2 256]\n",
      " [  0 128   8   8]]\n",
      "Q:  tensor([[0.8762, 0.8556, 0.9074, 0.7971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   8   2]\n",
      " [  0  16   2  16]\n",
      " [  0   0   2 256]\n",
      " [  4   0 128  16]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   8   2]\n",
      " [  0  16   2  16]\n",
      " [  0   0   2 256]\n",
      " [  4   0 128  16]]\n",
      "Q:  tensor([[0.9254, 0.9171, 0.2208, 0.4817]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  0   0   8  16]\n",
      " [  2   2   4 256]\n",
      " [  4  16 128  16]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  0   0   8  16]\n",
      " [  2   2   4 256]\n",
      " [  4  16 128  16]]\n",
      "Q:  tensor([[0.2718, 0.2190, 0.7197, 0.9647]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [  8  16   0   0]\n",
      " [  4   4 256   2]\n",
      " [  4  16 128  16]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [  8  16   0   0]\n",
      " [  4   4 256   2]\n",
      " [  4  16 128  16]]\n",
      "Q:  tensor([[0.8733, 0.6401, 0.6869, 0.8691]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   0]\n",
      " [  2  16   0   4]\n",
      " [  8   4 256   2]\n",
      " [  8  16 128  16]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   0]\n",
      " [  2  16   0   4]\n",
      " [  8   4 256   2]\n",
      " [  8  16 128  16]]\n",
      "Q:  tensor([[0.8894, 0.6040, 0.2215, 0.2985]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0   0]\n",
      " [  0  16   0   4]\n",
      " [  2   4 256   2]\n",
      " [ 16  16 128  16]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0   0]\n",
      " [  0  16   0   4]\n",
      " [  2   4 256   2]\n",
      " [ 16  16 128  16]]\n",
      "Q:  tensor([[0.2294, 0.4233, 0.8198, 0.8822]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   2]\n",
      " [ 16   4   0   0]\n",
      " [  2   4 256   2]\n",
      " [ 32 128  16   0]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   2]\n",
      " [ 16   4   0   0]\n",
      " [  2   4 256   2]\n",
      " [ 32 128  16   0]]\n",
      "Q:  tensor([[0.7457, 0.7353, 0.8337, 0.9030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   0   0]\n",
      " [ 16   4   0   0]\n",
      " [  2   4 256   2]\n",
      " [ 32 128  16   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   0   0]\n",
      " [ 16   4   0   0]\n",
      " [  2   4 256   2]\n",
      " [ 32 128  16   2]]\n",
      "Q:  tensor([[0.7169, 0.8244, 0.1691, 0.1091]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8 256   4]\n",
      " [ 16 128  16   0]\n",
      " [  2   0   0   0]\n",
      " [ 32   0   2   0]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8 256   4]\n",
      " [ 16 128  16   0]\n",
      " [  2   0   0   0]\n",
      " [ 32   0   2   0]]\n",
      "Q:  tensor([[ 0.1596,  0.3220,  0.2426, -0.0590]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8 256   4]\n",
      " [ 16 128  16   0]\n",
      " [  2   0   2   0]\n",
      " [ 32   0   2   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8 256   4]\n",
      " [ 16 128  16   0]\n",
      " [  2   0   2   0]\n",
      " [ 32   0   2   0]]\n",
      "Q:  tensor([[0.8199, 0.5552, 0.7652, 0.8027]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   2   0]\n",
      " [ 16   0 256   0]\n",
      " [  2   8  16   0]\n",
      " [ 32 128   4   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   2   0]\n",
      " [ 16   0 256   0]\n",
      " [  2   8  16   0]\n",
      " [ 32 128   4   4]]\n",
      "Q:  tensor([[0.0695, 0.2396, 0.7790, 0.5876]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   4   2]\n",
      " [  2   0  16 256]\n",
      " [  0   2   8  16]\n",
      " [  0  32 128   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   4   2]\n",
      " [  2   0  16 256]\n",
      " [  0   2   8  16]\n",
      " [  0  32 128   8]]\n",
      "Q:  tensor([[0.1144, 0.3307, 0.0194, 0.4741]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2   0   0]\n",
      " [  2  16 256   0]\n",
      " [  2   8  16   2]\n",
      " [ 32 128   8   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2   0   0]\n",
      " [  2  16 256   0]\n",
      " [  2   8  16   2]\n",
      " [ 32 128   8   0]]\n",
      "Q:  tensor([[ 0.9483,  0.9137,  0.3355, -0.1093]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   2   0]\n",
      " [  4  16 256   0]\n",
      " [  4   8  16   0]\n",
      " [ 32 128   8   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   2   0]\n",
      " [  4  16 256   0]\n",
      " [  4   8  16   0]\n",
      " [ 32 128   8   2]]\n",
      "Q:  tensor([[0.9795, 0.8821, 0.7921, 0.8133]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   2   2   0]\n",
      " [  0  16 256   0]\n",
      " [  8   8  16   0]\n",
      " [ 32 128   8   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   2   2   0]\n",
      " [  0  16 256   0]\n",
      " [  8   8  16   0]\n",
      " [ 32 128   8   2]]\n",
      "Q:  tensor([[0.2516, 0.6306, 0.6023, 1.0122]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4   0   2]\n",
      " [ 16 256   0   0]\n",
      " [ 16  16   0   0]\n",
      " [ 32 128   8   2]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4   0   2]\n",
      " [ 16 256   0   0]\n",
      " [ 16  16   0   0]\n",
      " [ 32 128   8   2]]\n",
      "Q:  tensor([[0.7636, 0.6965, 0.6437, 0.9246]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2   0   0]\n",
      " [ 16 256   0   2]\n",
      " [ 32   0   0   0]\n",
      " [ 32 128   8   2]]\n",
      "Reward: 40 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2   0   0]\n",
      " [ 16 256   0   2]\n",
      " [ 32   0   0   0]\n",
      " [ 32 128   8   2]]\n",
      "Q:  tensor([[0.8696, 0.8627, 0.3760, 0.3292]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   0]\n",
      " [ 64 128   8   4]]\n",
      "Reward: 68 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   0]\n",
      " [ 64 128   8   4]]\n",
      "Q:  tensor([[0.1272, 0.2826, 0.2476, 0.3611]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   0   0]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   0]\n",
      " [ 64 128   8   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   0   0]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   0]\n",
      " [ 64 128   8   4]]\n",
      "Q:  tensor([[0.6184, 0.7585, 0.6449, 0.8062]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   0   0]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   4]\n",
      " [ 64 128   8   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   0   0]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   4]\n",
      " [ 64 128   8   4]]\n",
      "Q:  tensor([[0.8417, 0.6260, 0.4450, 0.2364]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   0   4]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   0]\n",
      " [ 64 128   8   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   0   4]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   0]\n",
      " [ 64 128   8   8]]\n",
      "Q:  tensor([[0.4241, 0.4307, 0.7073, 0.7512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   0   2   0]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   0]\n",
      " [ 64 128  16   0]]\n",
      "Reward: 24 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   0   2   0]\n",
      " [  8   2   0   0]\n",
      " [ 16 256   0   0]\n",
      " [ 64 128  16   0]]\n",
      "Q:  tensor([[0.8197, 0.8782, 0.2242, 0.3276]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   2   2   0]\n",
      " [ 16 256  16   2]\n",
      " [ 64 128   0   0]\n",
      " [  0   0   0   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   2   2   0]\n",
      " [ 16 256  16   2]\n",
      " [ 64 128   0   0]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[0.7253, 0.7458, 0.6753, 0.8132]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   4   0   0]\n",
      " [ 16 256  16   2]\n",
      " [ 64 128   0   0]\n",
      " [  0   0   2   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   4   0   0]\n",
      " [ 16 256  16   2]\n",
      " [ 64 128   0   0]\n",
      " [  0   0   2   0]]\n",
      "Q:  tensor([[0.8997, 0.7151, 0.4941, 0.3125]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   0]\n",
      " [  2   4   0   0]\n",
      " [ 32 256  16   0]\n",
      " [ 64 128   2   2]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   0]\n",
      " [  2   4   0   0]\n",
      " [ 32 256  16   0]\n",
      " [ 64 128   2   2]]\n",
      "Q:  tensor([[-0.1367,  0.4799,  0.7956,  0.6760]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [  0   0   2   4]\n",
      " [  0  32 256  16]\n",
      " [  0  64 128   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [  0   0   2   4]\n",
      " [  0  32 256  16]\n",
      " [  0  64 128   4]]\n",
      "Q:  tensor([[0.2531, 0.2856, 0.0721, 0.3397]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [  2   4   0   0]\n",
      " [ 32 256  16   2]\n",
      " [ 64 128   4   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [  2   4   0   0]\n",
      " [ 32 256  16   2]\n",
      " [ 64 128   4   0]]\n",
      "Q:  tensor([[ 0.7471,  0.8539,  0.4784, -0.0166]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4  16   2]\n",
      " [ 32 256   4   0]\n",
      " [ 64 128   2   0]\n",
      " [  0   0   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4  16   2]\n",
      " [ 32 256   4   0]\n",
      " [ 64 128   2   0]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[ 0.3926, -0.0435,  0.7124,  0.8047]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8  16   2   0]\n",
      " [ 32 256   4   0]\n",
      " [ 64 128   2   0]\n",
      " [  2   0   0   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8  16   2   0]\n",
      " [ 32 256   4   0]\n",
      " [ 64 128   2   0]\n",
      " [  2   0   0   0]]\n",
      "Q:  tensor([[ 0.4301,  0.1078,  0.3156, -0.3288]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   0   0   0]\n",
      " [ 32  16   2   0]\n",
      " [ 64 256   4   0]\n",
      " [  2 128   2   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   0   0   0]\n",
      " [ 32  16   2   0]\n",
      " [ 64 256   4   0]\n",
      " [  2 128   2   2]]\n",
      "Q:  tensor([[0.1338, 0.4068, 0.9735, 0.7407]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   8]\n",
      " [  2  32  16   2]\n",
      " [  0  64 256   4]\n",
      " [  0   2 128   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   8]\n",
      " [  2  32  16   2]\n",
      " [  0  64 256   4]\n",
      " [  0   2 128   4]]\n",
      "Q:  tensor([[ 0.8420,  0.7687, -0.1612,  0.4204]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  0  32  16   8]\n",
      " [  0  64 256   2]\n",
      " [  2   2 128   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  0  32  16   8]\n",
      " [  0  64 256   2]\n",
      " [  2   2 128   8]]\n",
      "Q:  tensor([[-0.0524,  0.4489,  0.7095,  0.7731]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   0   0]\n",
      " [ 32  16   8   0]\n",
      " [ 64 256   2   0]\n",
      " [  4 128   8   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   0   0]\n",
      " [ 32  16   8   0]\n",
      " [ 64 256   2   0]\n",
      " [  4 128   8   0]]\n",
      "Q:  tensor([[-0.1739,  0.2767,  0.7481,  0.5730]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   4]\n",
      " [  0  32  16   8]\n",
      " [  0  64 256   2]\n",
      " [  2   4 128   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   4]\n",
      " [  0  32  16   8]\n",
      " [  0  64 256   2]\n",
      " [  2   4 128   8]]\n",
      "Q:  tensor([[-0.3494,  0.3233, -0.3948,  0.1593]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32  16   4]\n",
      " [  2  64 256   8]\n",
      " [  0   4 128   2]\n",
      " [  0   0   0   8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32  16   4]\n",
      " [  2  64 256   8]\n",
      " [  0   4 128   2]\n",
      " [  0   0   0   8]]\n",
      "Q:  tensor([[0.8462, 0.4572, 0.0418, 0.1644]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   4]\n",
      " [  2  32  16   8]\n",
      " [  0  64 256   2]\n",
      " [  4   4 128   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   4]\n",
      " [  2  32  16   8]\n",
      " [  0  64 256   2]\n",
      " [  4   4 128   8]]\n",
      "Q:  tensor([[0.4383, 0.4527, 0.8845, 0.6661]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   4]\n",
      " [  2  32  16   8]\n",
      " [  0  64 256   2]\n",
      " [  2   8 128   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   4]\n",
      " [  2  32  16   8]\n",
      " [  0  64 256   2]\n",
      " [  2   8 128   8]]\n",
      "Q:  tensor([[0.6468, 0.7538, 0.0300, 0.3226]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32  16   4]\n",
      " [  0  64 256   8]\n",
      " [  0   8 128   2]\n",
      " [  0   2   0   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32  16   4]\n",
      " [  0  64 256   8]\n",
      " [  0   8 128   2]\n",
      " [  0   2   0   8]]\n",
      "Q:  tensor([[ 0.2855, -0.0321,  0.0049,  0.3362]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32  16   4]\n",
      " [ 64 256   8   0]\n",
      " [  8 128   2   0]\n",
      " [  2   8   0   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32  16   4]\n",
      " [ 64 256   8   0]\n",
      " [  8 128   2   0]\n",
      " [  2   8   0   2]]\n",
      "Q:  tensor([[0.2167, 0.2633, 0.3536, 0.1967]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32  16   4]\n",
      " [  2  64 256   8]\n",
      " [  0   8 128   2]\n",
      " [  0   2   8   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32  16   4]\n",
      " [  2  64 256   8]\n",
      " [  0   8 128   2]\n",
      " [  0   2   8   2]]\n",
      "Q:  tensor([[ 0.7651,  0.7076, -0.2079,  0.4712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0  32  16   0]\n",
      " [  2  64 256   4]\n",
      " [  4   8 128   8]\n",
      " [  2   2   8   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0  32  16   0]\n",
      " [  2  64 256   4]\n",
      " [  4   8 128   8]\n",
      " [  2   2   8   4]]\n",
      "Q:  tensor([[0.1873, 0.3785, 0.7158, 0.8926]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32  16   0   2]\n",
      " [  2  64 256   4]\n",
      " [  4   8 128   8]\n",
      " [  4   8   4   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32  16   0   2]\n",
      " [  2  64 256   4]\n",
      " [  4   8 128   8]\n",
      " [  4   8   4   0]]\n",
      "Q:  tensor([[0.8617, 0.8866, 0.4871, 0.1980]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32  16 256   2]\n",
      " [  2  64 128   4]\n",
      " [  8  16   4   8]\n",
      " [  0   0   2   0]]\n",
      "Reward: 24 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32  16 256   2]\n",
      " [  2  64 128   4]\n",
      " [  8  16   4   8]\n",
      " [  0   0   2   0]]\n",
      "Q:  tensor([[0.2450, 0.0205, 0.3046, 0.3309]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32  16 256   2]\n",
      " [  2  64 128   4]\n",
      " [  8  16   4   8]\n",
      " [  2   0   2   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32  16 256   2]\n",
      " [  2  64 128   4]\n",
      " [  8  16   4   8]\n",
      " [  2   0   2   0]]\n",
      "Q:  tensor([[0.2692, 0.4310, 0.8842, 0.7718]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32  16 256   2]\n",
      " [  2  64 128   4]\n",
      " [  8  16   4   8]\n",
      " [  0   0   2   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32  16 256   2]\n",
      " [  2  64 128   4]\n",
      " [  8  16   4   8]\n",
      " [  0   0   2   4]]\n",
      "Q:  tensor([[ 0.4273, -0.0195,  0.0610,  0.3801]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2 256   2]\n",
      " [ 32  16 128   4]\n",
      " [  2  64   4   8]\n",
      " [  8  16   2   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2 256   2]\n",
      " [ 32  16 128   4]\n",
      " [  2  64   4   8]\n",
      " [  8  16   2   4]]\n",
      "Q:  tensor([[0.2096, 0.2869, 0.2200, 0.3490]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2 256   2   2]\n",
      " [ 32  16 128   4]\n",
      " [  2  64   4   8]\n",
      " [  8  16   2   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2 256   2   2]\n",
      " [ 32  16 128   4]\n",
      " [  2  64   4   8]\n",
      " [  8  16   2   4]]\n",
      "Q:  tensor([[ 0.2342, -0.0039,  0.9552,  0.5998]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2 256   4]\n",
      " [ 32  16 128   4]\n",
      " [  2  64   4   8]\n",
      " [  8  16   2   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2 256   4]\n",
      " [ 32  16 128   4]\n",
      " [  2  64   4   8]\n",
      " [  8  16   2   4]]\n",
      "Q:  tensor([[0.8622, 0.9673, 0.8359, 0.7881]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2 256   8]\n",
      " [ 32  16 128   8]\n",
      " [  2  64   4   4]\n",
      " [  8  16   2   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2 256   8]\n",
      " [ 32  16 128   8]\n",
      " [  2  64   4   4]\n",
      " [  8  16   2   2]]\n",
      "Q:  tensor([[0.9086, 0.8182, 1.0562, 0.6294]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   4 256   8]\n",
      " [ 32  16 128   8]\n",
      " [  4   2  64   8]\n",
      " [  0   8  16   4]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   4 256   8]\n",
      " [ 32  16 128   8]\n",
      " [  4   2  64   8]\n",
      " [  0   8  16   4]]\n",
      "Q:  tensor([[0.7796, 0.8486, 0.0292, 0.0499]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32   4 256  16]\n",
      " [  4  16 128   8]\n",
      " [  0   2  64   4]\n",
      " [  2   8  16   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32   4 256  16]\n",
      " [  4  16 128   8]\n",
      " [  0   2  64   4]\n",
      " [  2   8  16   0]]\n",
      "Q:  tensor([[0.1032, 0.3378, 0.1929, 0.1872]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32   4 256  16]\n",
      " [  4  16 128   8]\n",
      " [  2   2  64   4]\n",
      " [  0   8  16   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32   4 256  16]\n",
      " [  4  16 128   8]\n",
      " [  2   2  64   4]\n",
      " [  0   8  16   2]]\n",
      "Q:  tensor([[0.1671, 0.1498, 0.7645, 0.9138]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32   4 256  16]\n",
      " [  4  16 128   8]\n",
      " [  4  64   4   2]\n",
      " [  8  16   2   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32   4 256  16]\n",
      " [  4  16 128   8]\n",
      " [  4  64   4   2]\n",
      " [  8  16   2   0]]\n",
      "Q:  tensor([[0.9501, 0.8559, 0.4923, 0.0947]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   4 256   2]\n",
      " [ 32  16 128  16]\n",
      " [  8  64   4   8]\n",
      " [  8  16   2   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   4 256   2]\n",
      " [ 32  16 128  16]\n",
      " [  8  64   4   8]\n",
      " [  8  16   2   2]]\n",
      "Q:  tensor([[0.8267, 0.7492, 0.7559, 0.7819]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   2]\n",
      " [  0  16 128  16]\n",
      " [ 32  64   4   8]\n",
      " [ 16  16   2   2]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   2]\n",
      " [  0  16 128  16]\n",
      " [ 32  64   4   8]\n",
      " [ 16  16   2   2]]\n",
      "Q:  tensor([[0.4284, 0.4416, 0.7385, 0.8451]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   0]\n",
      " [ 32  64   4   8]\n",
      " [ 32   4   2   2]]\n",
      "Reward: 36 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   0]\n",
      " [ 32  64   4   8]\n",
      " [ 32   4   2   2]]\n",
      "Q:  tensor([[0.8041, 0.7489, 0.8152, 0.9815]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   0]\n",
      " [ 32  64   4   8]\n",
      " [ 32   4   4   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   0]\n",
      " [ 32  64   4   8]\n",
      " [ 32   4   4   2]]\n",
      "Q:  tensor([[0.7714, 0.9107, 0.8803, 0.7088]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   8]\n",
      " [ 64  64   8   2]\n",
      " [  0   4   2   0]]\n",
      "Reward: 72 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   8]\n",
      " [ 64  64   8   2]\n",
      " [  0   4   2   0]]\n",
      "Q:  tensor([[0.4995, 0.2292, 0.6998, 0.8536]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   8]\n",
      " [128   8   2   2]\n",
      " [  4   2   0   0]]\n",
      "Reward: 128 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   8]\n",
      " [128   8   2   2]\n",
      " [  4   2   0   0]]\n",
      "Q:  tensor([[ 0.5705, -0.0397,  0.8664,  0.8386]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   8]\n",
      " [  2 128   8   4]\n",
      " [  0   0   4   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   8]\n",
      " [  2 128   8   4]\n",
      " [  0   0   4   2]]\n",
      "Q:  tensor([[ 0.3438, -0.2835, -0.1480,  0.3741]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   8]\n",
      " [  2 128   8   4]\n",
      " [  4   2   4   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   2]\n",
      " [ 16 128  16   8]\n",
      " [  2 128   8   4]\n",
      " [  4   2   4   0]]\n",
      "Q:  tensor([[ 0.4813, -0.1494,  0.3896,  0.0923]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2 256   0]\n",
      " [ 16   4  16   2]\n",
      " [  2 256   8   8]\n",
      " [  4   2   4   4]]\n",
      "Reward: 256 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2 256   0]\n",
      " [ 16   4  16   2]\n",
      " [  2 256   8   8]\n",
      " [  4   2   4   4]]\n",
      "Q:  tensor([[0.1936, 0.0646, 0.8650, 0.7512]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   4 256]\n",
      " [ 16   4  16   2]\n",
      " [  0   2 256  16]\n",
      " [  0   4   2   8]]\n",
      "Reward: 28 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   4 256]\n",
      " [ 16   4  16   2]\n",
      " [  0   2 256  16]\n",
      " [  0   4   2   8]]\n",
      "Q:  tensor([[0.2558, 0.3575, 0.3548, 0.4181]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   0]\n",
      " [ 16   4  16   2]\n",
      " [  2 256  16   2]\n",
      " [  4   2   8   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   0]\n",
      " [ 16   4  16   2]\n",
      " [  2 256  16   2]\n",
      " [  4   2   8   0]]\n",
      "Q:  tensor([[ 0.8222,  0.7866,  0.2841, -0.2990]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [ 16   8 256   0]\n",
      " [  2 256  32   2]\n",
      " [  4   2   8   4]]\n",
      "Reward: 44 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [ 16   8 256   0]\n",
      " [  2 256  32   2]\n",
      " [  4   2   8   4]]\n",
      "Q:  tensor([[-0.1821,  0.3520,  0.3887, -0.2271]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   2]\n",
      " [  0  16   8 256]\n",
      " [  2 256  32   2]\n",
      " [  4   2   8   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   2]\n",
      " [  0  16   8 256]\n",
      " [  2 256  32   2]\n",
      " [  4   2   8   4]]\n",
      "Q:  tensor([[0.9160, 0.8923, 0.7144, 0.7131]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   2]\n",
      " [  0  16   8 256]\n",
      " [  4 256  32   2]\n",
      " [  4   2   8   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   2]\n",
      " [  0  16   8 256]\n",
      " [  4 256  32   2]\n",
      " [  4   2   8   4]]\n",
      "Q:  tensor([[0.7713, 0.8959, 0.6495, 0.9038]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   2   0]\n",
      " [ 16   8 256   0]\n",
      " [  4 256  32   2]\n",
      " [  4   2   8   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   2   0]\n",
      " [ 16   8 256   0]\n",
      " [  4 256  32   2]\n",
      " [  4   2   8   4]]\n",
      "Q:  tensor([[0.7889, 0.9657, 0.3918, 0.2817]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8   2   2]\n",
      " [ 16 256 256   4]\n",
      " [  8   2  32   2]\n",
      " [  0   0   8   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8   2   2]\n",
      " [ 16 256 256   4]\n",
      " [  8   2  32   2]\n",
      " [  0   0   8   0]]\n",
      "Q:  tensor([[ 0.4613, -0.1011,  0.8018,  0.8211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8   4   0]\n",
      " [ 16 512   4   0]\n",
      " [  8   2  32   2]\n",
      " [  8   0   2   0]]\n",
      "Reward: 516 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8   4   0]\n",
      " [ 16 512   4   0]\n",
      " [  8   2  32   2]\n",
      " [  8   0   2   0]]\n",
      "Q:  tensor([[0.8549, 0.9334, 0.6048, 0.4879]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8   8   2]\n",
      " [ 16 512  32   0]\n",
      " [ 16   2   2   0]\n",
      " [  0   2   0   0]]\n",
      "Reward: 24 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8   8   2]\n",
      " [ 16 512  32   0]\n",
      " [ 16   2   2   0]\n",
      " [  0   2   0   0]]\n",
      "Q:  tensor([[0.8368, 0.8666, 0.7664, 0.8861]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16   2   0]\n",
      " [ 16 512  32   0]\n",
      " [ 16   4   0   2]\n",
      " [  2   0   0   0]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16   2   0]\n",
      " [ 16 512  32   0]\n",
      " [ 16   4   0   2]\n",
      " [  2   0   0   0]]\n",
      "Q:  tensor([[0.8795, 0.7566, 0.4786, 0.4836]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0   0]\n",
      " [  4  16   0   0]\n",
      " [ 32 512   2   0]\n",
      " [  2   4  32   2]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0   0]\n",
      " [  4  16   0   0]\n",
      " [ 32 512   2   0]\n",
      " [  2   4  32   2]]\n",
      "Q:  tensor([[-0.1073,  0.4219,  0.4225,  0.0842]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0   2]\n",
      " [  0   0   4  16]\n",
      " [  0  32 512   2]\n",
      " [  2   4  32   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0   2]\n",
      " [  0   0   4  16]\n",
      " [  0  32 512   2]\n",
      " [  2   4  32   2]]\n",
      "Q:  tensor([[0.8897, 0.9084, 0.8572, 0.8883]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   4   2]\n",
      " [  0  32 512  16]\n",
      " [  0   4  32   4]\n",
      " [  0   0   0   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   4   2]\n",
      " [  0  32 512  16]\n",
      " [  0   4  32   4]\n",
      " [  0   0   0   2]]\n",
      "Q:  tensor([[0.4522, 0.0248, 0.8502, 1.0033]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4   2   0]\n",
      " [ 32 512  16   4]\n",
      " [  4  32   4   0]\n",
      " [  2   0   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4   2   0]\n",
      " [ 32 512  16   4]\n",
      " [  4  32   4   0]\n",
      " [  2   0   0   0]]\n",
      "Q:  tensor([[0.4938, 0.4590, 0.7544, 0.8251]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   2   0   0]\n",
      " [ 32 512  16   4]\n",
      " [  4  32   4   0]\n",
      " [  2   0   0   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   2   0   0]\n",
      " [ 32 512  16   4]\n",
      " [  4  32   4   0]\n",
      " [  2   0   0   2]]\n",
      "Q:  tensor([[0.4302, 0.4203, 0.9031, 0.7805]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   8   2]\n",
      " [ 32 512  16   4]\n",
      " [  0   4  32   4]\n",
      " [  0   2   0   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   8   2]\n",
      " [ 32 512  16   4]\n",
      " [  0   4  32   4]\n",
      " [  0   2   0   4]]\n",
      "Q:  tensor([[0.8362, 0.7271, 0.4406, 0.5630]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [  0 512   8   2]\n",
      " [  0   4  16   4]\n",
      " [ 32   2  32   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [  0 512   8   2]\n",
      " [  0   4  16   4]\n",
      " [ 32   2  32   8]]\n",
      "Q:  tensor([[0.1098, 0.3149, 0.1288, 0.4988]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   4   0]\n",
      " [512   8   2   0]\n",
      " [  4  16   4   0]\n",
      " [ 32   2  32   8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   4   0]\n",
      " [512   8   2   0]\n",
      " [  4  16   4   0]\n",
      " [ 32   2  32   8]]\n",
      "Q:  tensor([[-0.2976,  0.2147,  0.2863, -0.3211]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2   4]\n",
      " [  2 512   8   2]\n",
      " [  0   4  16   4]\n",
      " [ 32   2  32   8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2   4]\n",
      " [  2 512   8   2]\n",
      " [  0   4  16   4]\n",
      " [ 32   2  32   8]]\n",
      "Q:  tensor([[ 0.2207,  0.4779, -0.0815,  0.4728]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2 512   2   4]\n",
      " [ 32   4   8   2]\n",
      " [  2   2  16   4]\n",
      " [  0   0  32   8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2 512   2   4]\n",
      " [ 32   4   8   2]\n",
      " [  2   2  16   4]\n",
      " [  0   0  32   8]]\n",
      "Q:  tensor([[0.5247, 0.1540, 0.9980, 0.7683]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2 512   2   4]\n",
      " [ 32   4   8   2]\n",
      " [  2   4  16   4]\n",
      " [  0   0  32   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2 512   2   4]\n",
      " [ 32   4   8   2]\n",
      " [  2   4  16   4]\n",
      " [  0   0  32   8]]\n",
      "Q:  tensor([[0.9001, 0.7984, 0.1920, 0.1040]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   2   4]\n",
      " [  2   0   8   2]\n",
      " [ 32 512  16   4]\n",
      " [  2   8  32   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   2   4]\n",
      " [  2   0   8   2]\n",
      " [ 32 512  16   4]\n",
      " [  2   8  32   8]]\n",
      "Q:  tensor([[0.3969, 0.4761, 0.7813, 0.8818]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4   2   0]\n",
      " [  2   8   2   0]\n",
      " [ 32 512  16   4]\n",
      " [  2   8  32   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4   2   0]\n",
      " [  2   8   2   0]\n",
      " [ 32 512  16   4]\n",
      " [  2   8  32   8]]\n",
      "Q:  tensor([[0.8228, 0.9678, 0.9061, 0.7521]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4   4   4]\n",
      " [  2   8  16   8]\n",
      " [ 32 512  32   0]\n",
      " [  2   8   0   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4   4   4]\n",
      " [  2   8  16   8]\n",
      " [ 32 512  32   0]\n",
      " [  2   8   0   2]]\n",
      "Q:  tensor([[0.2207, 0.4448, 0.8551, 0.9847]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   8   4   0]\n",
      " [  2   8  16   8]\n",
      " [ 32 512  32   0]\n",
      " [  2   8   2   2]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   8   4   0]\n",
      " [  2   8  16   8]\n",
      " [ 32 512  32   0]\n",
      " [  2   8   2   2]]\n",
      "Q:  tensor([[0.6513, 0.7919, 0.8187, 0.7643]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2  16   4]\n",
      " [  2   8  16   8]\n",
      " [  0  32 512  32]\n",
      " [  0   2   8   4]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2  16   4]\n",
      " [  2   8  16   8]\n",
      " [  0  32 512  32]\n",
      " [  0   2   8   4]]\n",
      "Q:  tensor([[0.8868, 0.8888, 0.1376, 0.2573]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2  32   4]\n",
      " [  0   8 512   8]\n",
      " [  0  32   8  32]\n",
      " [  4   2   0   4]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2  32   4]\n",
      " [  0   8 512   8]\n",
      " [  0  32   8  32]\n",
      " [  4   2   0   4]]\n",
      "Q:  tensor([[ 0.4304, -0.1036,  0.5227,  0.6613]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   4   0]\n",
      " [  8 512   8   0]\n",
      " [ 32   8  32   0]\n",
      " [  4   2   4   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   4   0]\n",
      " [  8 512   8   0]\n",
      " [ 32   8  32   0]\n",
      " [  4   2   4   2]]\n",
      "Q:  tensor([[-0.1425,  0.4576,  0.3458, -0.2831]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   4   2]\n",
      " [  8 512   8   2]\n",
      " [ 32   8  32   0]\n",
      " [  4   2   4   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   4   2]\n",
      " [  8 512   8   2]\n",
      " [ 32   8  32   0]\n",
      " [  4   2   4   0]]\n",
      "Q:  tensor([[ 0.7900,  0.8606,  0.1619, -0.0276]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   4   4]\n",
      " [  8 512   8   0]\n",
      " [ 32   8  32   2]\n",
      " [  4   2   4   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   4   4]\n",
      " [  8 512   8   0]\n",
      " [ 32   8  32   2]\n",
      " [  4   2   4   0]]\n",
      "Q:  tensor([[0.2884, 0.1733, 0.8692, 0.8633]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   4  32   8]\n",
      " [  0   8 512   8]\n",
      " [ 32   8  32   2]\n",
      " [  2   4   2   4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   4  32   8]\n",
      " [  0   8 512   8]\n",
      " [ 32   8  32   2]\n",
      " [  2   4   2   4]]\n",
      "Q:  tensor([[0.8197, 0.7314, 0.3699, 0.1945]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0  32   0]\n",
      " [  0   4 512  16]\n",
      " [ 32  16  32   2]\n",
      " [  2   4   2   4]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0  32   0]\n",
      " [  0   4 512  16]\n",
      " [ 32  16  32   2]\n",
      " [  2   4   2   4]]\n",
      "Q:  tensor([[0.4296, 0.4401, 0.3619, 0.3574]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4  32  16]\n",
      " [ 32  16 512   2]\n",
      " [  2   4  32   4]\n",
      " [  0   2   2   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4  32  16]\n",
      " [ 32  16 512   2]\n",
      " [  2   4  32   4]\n",
      " [  0   2   2   0]]\n",
      "Q:  tensor([[ 0.2899, -0.0019,  0.8718,  0.8587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4  32  16]\n",
      " [ 32  16 512   2]\n",
      " [  2   4  32   4]\n",
      " [  2   0   0   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4  32  16]\n",
      " [ 32  16 512   2]\n",
      " [  2   4  32   4]\n",
      " [  2   0   0   4]]\n",
      "Q:  tensor([[0.9556, 0.7915, 0.2762, 0.1501]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2   0]\n",
      " [  2   4  32  16]\n",
      " [ 32  16 512   2]\n",
      " [  4   4  32   8]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2   0]\n",
      " [  2   4  32  16]\n",
      " [ 32  16 512   2]\n",
      " [  4   4  32   8]]\n",
      "Q:  tensor([[0.2647, 0.4850, 0.7742, 0.8586]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [  2   4  32  16]\n",
      " [ 32  16 512   2]\n",
      " [  8  32   8   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [  2   4  32  16]\n",
      " [ 32  16 512   2]\n",
      " [  8  32   8   2]]\n",
      "Q:  tensor([[0.8019, 0.7567, 0.3562, 0.0971]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2   0]\n",
      " [  4   4  32   0]\n",
      " [ 32  16 512  16]\n",
      " [  8  32   8   4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2   0]\n",
      " [  4   4  32   0]\n",
      " [ 32  16 512  16]\n",
      " [  8  32   8   4]]\n",
      "Q:  tensor([[-0.1434,  0.4525,  0.7395,  0.7953]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   0]\n",
      " [  8  32   0   2]\n",
      " [ 32  16 512  16]\n",
      " [  8  32   8   4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   0]\n",
      " [  8  32   0   2]\n",
      " [ 32  16 512  16]\n",
      " [  8  32   8   4]]\n",
      "Q:  tensor([[-0.0632,  0.2425,  0.2529,  0.2915]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   0   0]\n",
      " [  8  32   2   0]\n",
      " [ 32  16 512  16]\n",
      " [  8  32   8   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   0   0]\n",
      " [  8  32   2   0]\n",
      " [ 32  16 512  16]\n",
      " [  8  32   8   4]]\n",
      "Q:  tensor([[-0.1397,  0.4635,  0.7648,  0.6466]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2   4]\n",
      " [  0   8  32   2]\n",
      " [ 32  16 512  16]\n",
      " [  8  32   8   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2   4]\n",
      " [  0   8  32   2]\n",
      " [ 32  16 512  16]\n",
      " [  8  32   8   4]]\n",
      "Q:  tensor([[-0.2900,  0.2928, -0.3617,  0.2079]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32   8   2   4]\n",
      " [  8  16  32   2]\n",
      " [  0  32 512  16]\n",
      " [  0   2   8   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32   8   2   4]\n",
      " [  8  16  32   2]\n",
      " [  0  32 512  16]\n",
      " [  0   2   8   4]]\n",
      "Q:  tensor([[ 0.1294, -0.3712, -0.4520,  0.2718]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32   8   2   4]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  16   0]\n",
      " [  2   8   4   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32   8   2   4]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  16   0]\n",
      " [  2   8   4   2]]\n",
      "Q:  tensor([[0.9071, 0.7151, 0.3228, 0.0523]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32   8   2   2]\n",
      " [  8  16  32   0]\n",
      " [ 32 512  16   4]\n",
      " [  2   8   4   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32   8   2   2]\n",
      " [  8  16  32   0]\n",
      " [ 32 512  16   4]\n",
      " [  2   8   4   4]]\n",
      "Q:  tensor([[0.8266, 0.8216, 0.8371, 0.8722]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 32   8   4   0]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  16   4]\n",
      " [  2   8   8   0]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 32   8   4   0]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  16   4]\n",
      " [  2   8   8   0]]\n",
      "Q:  tensor([[0.4701, 0.4012, 0.9587, 0.8188]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   8   4]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  16   4]\n",
      " [  0   0   2  16]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   8   4]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  16   4]\n",
      " [  0   0   2  16]]\n",
      "Q:  tensor([[ 0.1990, -0.3402, -0.3244,  0.5355]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   8   4]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  16   4]\n",
      " [  2  16   4   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   8   4]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  16   4]\n",
      " [  2  16   4   0]]\n",
      "Q:  tensor([[ 0.3755, -0.2109,  0.3591, -0.1687]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   8   4]\n",
      " [  8  16  32   4]\n",
      " [ 32 512  16   2]\n",
      " [  2  16   4   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   8   4]\n",
      " [  8  16  32   4]\n",
      " [ 32 512  16   2]\n",
      " [  2  16   4   4]]\n",
      "Q:  tensor([[0.7931, 0.7225, 0.8463, 0.6589]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   8   4]\n",
      " [  8  16  32   4]\n",
      " [ 32 512  16   2]\n",
      " [  2   2  16   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   8   4]\n",
      " [  8  16  32   4]\n",
      " [ 32 512  16   2]\n",
      " [  2   2  16   8]]\n",
      "Q:  tensor([[0.7947, 0.9220, 0.9037, 0.6048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   8   8]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  32   8]\n",
      " [  2   2   0   2]]\n",
      "Reward: 40 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   8   8]\n",
      " [  8  16  32   2]\n",
      " [ 32 512  32   8]\n",
      " [  2   2   0   2]]\n",
      "Q:  tensor([[0.7358, 0.6821, 0.6715, 0.7019]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   2   8]\n",
      " [  8  16   0   2]\n",
      " [ 32 512   8   8]\n",
      " [  2   2  64   2]]\n",
      "Reward: 64 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   2   8]\n",
      " [  8  16   0   2]\n",
      " [ 32 512   8   8]\n",
      " [  2   2  64   2]]\n",
      "Q:  tensor([[0.3754, 0.3826, 0.8565, 0.9226]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   2   8]\n",
      " [  8  16   2   0]\n",
      " [ 32 512  16   0]\n",
      " [  4  64   2   2]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   2   8]\n",
      " [  8  16   2   0]\n",
      " [ 32 512  16   0]\n",
      " [  4  64   2   2]]\n",
      "Q:  tensor([[0.5697, 0.8725, 0.8046, 0.8803]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   2   8]\n",
      " [  8  16   2   0]\n",
      " [ 32 512  16   0]\n",
      " [  4  64   4   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   2   8]\n",
      " [  8  16   2   0]\n",
      " [ 32 512  16   0]\n",
      " [  4  64   4   4]]\n",
      "Q:  tensor([[0.7922, 0.8813, 0.8767, 0.6895]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   4   8]\n",
      " [  8  16  16   4]\n",
      " [ 32 512   4   2]\n",
      " [  4  64   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   4   8]\n",
      " [  8  16  16   4]\n",
      " [ 32 512   4   2]\n",
      " [  4  64   0   0]]\n",
      "Q:  tensor([[0.2904, 0.0762, 0.9044, 0.8113]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   4   8]\n",
      " [  0   8  32   4]\n",
      " [ 32 512   4   2]\n",
      " [  2   0   4  64]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   4   8]\n",
      " [  0   8  32   4]\n",
      " [ 32 512   4   2]\n",
      " [  2   0   4  64]]\n",
      "Q:  tensor([[0.8475, 0.7660, 0.4928, 0.3278]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   8]\n",
      " [  2  32   4   4]\n",
      " [ 32   8  32   2]\n",
      " [  2 512   8  64]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   8]\n",
      " [  2  32   4   4]\n",
      " [ 32   8  32   2]\n",
      " [  2 512   8  64]]\n",
      "Q:  tensor([[0.7338, 0.9378, 0.9006, 0.7762]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   4   8]\n",
      " [ 32   8  32   4]\n",
      " [  2 512   8   2]\n",
      " [  2   0   0  64]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   4   8]\n",
      " [ 32   8  32   4]\n",
      " [  2 512   8   2]\n",
      " [  2   0   0  64]]\n",
      "Q:  tensor([[0.7019, 0.6374, 0.1276, 0.3477]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   8]\n",
      " [  4  32   4   4]\n",
      " [ 32   8  32   2]\n",
      " [  4 512   8  64]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   8]\n",
      " [  4  32   4   4]\n",
      " [ 32   8  32   2]\n",
      " [  4 512   8  64]]\n",
      "Q:  tensor([[0.1994, 0.5478, 0.9026, 0.8363]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   2   8]\n",
      " [  0   4  32   8]\n",
      " [ 32   8  32   2]\n",
      " [  4 512   8  64]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   2   8]\n",
      " [  0   4  32   8]\n",
      " [ 32   8  32   2]\n",
      " [  4 512   8  64]]\n",
      "Q:  tensor([[0.8409, 0.8360, 0.6375, 0.9087]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8   0   2]\n",
      " [  4  32   8   0]\n",
      " [ 32   8  32   2]\n",
      " [  4 512   8  64]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8   0   2]\n",
      " [  4  32   8   0]\n",
      " [ 32   8  32   2]\n",
      " [  4 512   8  64]]\n",
      "Q:  tensor([[0.6287, 0.8714, 0.2835, 0.3462]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   8   8   4]\n",
      " [ 32  32  32  64]\n",
      " [  4   8   8   0]\n",
      " [  0 512   2   0]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   8   8   4]\n",
      " [ 32  32  32  64]\n",
      " [  4   8   8   0]\n",
      " [  0 512   2   0]]\n",
      "Q:  tensor([[0.4599, 0.2604, 0.4533, 0.8401]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   8   4   0]\n",
      " [ 64  32  64   0]\n",
      " [  4  16   2   0]\n",
      " [512   2   0   0]]\n",
      "Reward: 96 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   8   4   0]\n",
      " [ 64  32  64   0]\n",
      " [  4  16   2   0]\n",
      " [512   2   0   0]]\n",
      "Q:  tensor([[ 0.3149,  0.0369,  0.3362, -0.2183]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0  16   8   4]\n",
      " [  0  64  32  64]\n",
      " [  2   4  16   2]\n",
      " [  0   0 512   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0  16   8   4]\n",
      " [  0  64  32  64]\n",
      " [  2   4  16   2]\n",
      " [  0   0 512   2]]\n",
      "Q:  tensor([[ 0.8534,  0.6214, -0.1328,  0.3864]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   8   2]\n",
      " [  0  16  32   4]\n",
      " [  0  64  16  64]\n",
      " [  2   4 512   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   8   2]\n",
      " [  0  16  32   4]\n",
      " [  0  64  16  64]\n",
      " [  2   4 512   4]]\n",
      "Q:  tensor([[-0.1711,  0.4662, -0.2830,  0.3085]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16   8   2]\n",
      " [  0  64  32   4]\n",
      " [  0   4  16  64]\n",
      " [  4   0 512   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16   8   2]\n",
      " [  0  64  32   4]\n",
      " [  0   4  16  64]\n",
      " [  4   0 512   4]]\n",
      "Q:  tensor([[0.4166, 0.3488, 0.3643, 0.5352]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16   8   2]\n",
      " [ 64  32   4   0]\n",
      " [  4  16  64   2]\n",
      " [  4 512   4   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16   8   2]\n",
      " [ 64  32   4   0]\n",
      " [  4  16  64   2]\n",
      " [  4 512   4   0]]\n",
      "Q:  tensor([[0.8379, 0.6499, 0.2794, 0.2137]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0  16   8   0]\n",
      " [  2  32   4   0]\n",
      " [ 64  16  64   2]\n",
      " [  8 512   4   4]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0  16   8   0]\n",
      " [  2  32   4   0]\n",
      " [ 64  16  64   2]\n",
      " [  8 512   4   4]]\n",
      "Q:  tensor([[0.2438, 0.4051, 0.7029, 0.7705]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   8   0   0]\n",
      " [  2  32   4   2]\n",
      " [ 64  16  64   2]\n",
      " [  8 512   8   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   8   0   0]\n",
      " [  2  32   4   2]\n",
      " [ 64  16  64   2]\n",
      " [  8 512   8   0]]\n",
      "Q:  tensor([[0.7235, 0.9235, 0.2982, 0.0792]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   8   4   4]\n",
      " [  2  32  64   0]\n",
      " [ 64  16   8   2]\n",
      " [  8 512   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   8   4   4]\n",
      " [  2  32  64   0]\n",
      " [ 64  16   8   2]\n",
      " [  8 512   0   0]]\n",
      "Q:  tensor([[0.2718, 0.2043, 0.9362, 0.7544]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16   8   8]\n",
      " [  0   2  32  64]\n",
      " [ 64  16   8   2]\n",
      " [  0   0   8 512]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16   8   8]\n",
      " [  0   2  32  64]\n",
      " [ 64  16   8   2]\n",
      " [  0   0   8 512]]\n",
      "Q:  tensor([[0.7026, 0.9122, 0.9123, 0.7820]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   4  16  16]\n",
      " [  0   2  32  64]\n",
      " [ 64  16   8   2]\n",
      " [  2   0   8 512]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   4  16  16]\n",
      " [  0   2  32  64]\n",
      " [ 64  16   8   2]\n",
      " [  2   0   8 512]]\n",
      "Q:  tensor([[0.7970, 0.8949, 0.7202, 0.8165]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 64   4  16  16]\n",
      " [  2   2  32  64]\n",
      " [  0  16  16   2]\n",
      " [  2   0   0 512]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 64   4  16  16]\n",
      " [  2   2  32  64]\n",
      " [  0  16  16   2]\n",
      " [  2   0   0 512]]\n",
      "Q:  tensor([[0.6590, 0.8348, 0.7268, 0.8269]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 64   4  16  16]\n",
      " [  4   2  32  64]\n",
      " [  2  16  16   2]\n",
      " [  0   0   0 512]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 64   4  16  16]\n",
      " [  4   2  32  64]\n",
      " [  2  16  16   2]\n",
      " [  0   0   0 512]]\n",
      "Q:  tensor([[0.3752, 0.3336, 0.8725, 0.8776]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 64   4  32   0]\n",
      " [  4   2  32  64]\n",
      " [  2  32   2   0]\n",
      " [512   0   2   0]]\n",
      "Reward: 64 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 64   4  32   0]\n",
      " [  4   2  32  64]\n",
      " [  2  32   2   0]\n",
      " [512   0   2   0]]\n",
      "Q:  tensor([[0.8565, 0.7323, 0.3157, 0.4411]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 64   0   0   2]\n",
      " [  4   4  32   0]\n",
      " [  2   2  64   0]\n",
      " [512  32   4  64]]\n",
      "Reward: 68 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 64   0   0   2]\n",
      " [  4   4  32   0]\n",
      " [  2   2  64   0]\n",
      " [512  32   4  64]]\n",
      "Q:  tensor([[0.1206, 0.2937, 0.7417, 0.9384]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 64   2   0   0]\n",
      " [  8  32   2   0]\n",
      " [  4  64   0   0]\n",
      " [512  32   4  64]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 64   2   0   0]\n",
      " [  8  32   2   0]\n",
      " [  4  64   0   0]\n",
      " [512  32   4  64]]\n",
      "Q:  tensor([[0.2305, 0.3090, 0.3305, 0.2210]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0  64   2]\n",
      " [  0   8  32   2]\n",
      " [  2   0   4  64]\n",
      " [512  32   4  64]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0  64   2]\n",
      " [  0   8  32   2]\n",
      " [  2   0   4  64]\n",
      " [512  32   4  64]]\n",
      "Q:  tensor([[0.8179, 0.7874, 0.5242, 0.5416]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  0   0  64   2]\n",
      " [  2   8  32   4]\n",
      " [512  32   8 128]]\n",
      "Reward: 140 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  0   0  64   2]\n",
      " [  2   8  32   4]\n",
      " [512  32   8 128]]\n",
      "Q:  tensor([[ 0.8561,  0.9079, -0.0717,  0.3472]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8  64   4]\n",
      " [512  32  32   4]\n",
      " [  0   0   8 128]\n",
      " [  0   0   0   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   8  64   4]\n",
      " [512  32  32   4]\n",
      " [  0   0   8 128]\n",
      " [  0   0   0   4]]\n",
      "Q:  tensor([[0.6085, 0.7764, 0.8051, 0.6048]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8  64   4]\n",
      " [  0 512  64   4]\n",
      " [  0   0   8 128]\n",
      " [  2   0   0   4]]\n",
      "Reward: 64 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   8  64   4]\n",
      " [  0 512  64   4]\n",
      " [  0   0   8 128]\n",
      " [  2   0   0   4]]\n",
      "Q:  tensor([[0.7830, 0.8000, 0.5025, 0.2774]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8 128   8]\n",
      " [  0 512   8 128]\n",
      " [  0   0   2   4]\n",
      " [  0   0   0   0]]\n",
      "Reward: 140 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8 128   8]\n",
      " [  0 512   8 128]\n",
      " [  0   0   2   4]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[ 0.2357, -0.3152, -0.4129,  0.3552]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8 128   8]\n",
      " [512   8 128   0]\n",
      " [  2   4   0   0]\n",
      " [  0   0   0   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8 128   8]\n",
      " [512   8 128   0]\n",
      " [  2   4   0   0]\n",
      " [  0   0   0   2]]\n",
      "Q:  tensor([[0.7900, 0.8536, 0.3211, 0.1982]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16 256   8]\n",
      " [512   4   2   2]\n",
      " [  2   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "Reward: 272 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16 256   8]\n",
      " [512   4   2   2]\n",
      " [  2   0   0   0]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[0.4081, 0.1127, 0.8858, 0.8559]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16 256   8]\n",
      " [  0 512   4   4]\n",
      " [  0   0   0   2]\n",
      " [  0   2   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16 256   8]\n",
      " [  0 512   4   4]\n",
      " [  0   0   0   2]\n",
      " [  0   2   0   0]]\n",
      "Q:  tensor([[0.4592, 0.3580, 0.8571, 0.9052]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16 256   8]\n",
      " [512   8   0   0]\n",
      " [  2   0   2   0]\n",
      " [  2   0   0   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16 256   8]\n",
      " [512   8   0   0]\n",
      " [  2   0   2   0]\n",
      " [  2   0   0   0]]\n",
      "Q:  tensor([[0.8315, 0.7514, 0.6487, 0.8556]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16 256   8]\n",
      " [512   8   0   0]\n",
      " [  4   0   0   2]\n",
      " [  2   0   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16 256   8]\n",
      " [512   8   0   0]\n",
      " [  4   0   0   2]\n",
      " [  2   0   0   0]]\n",
      "Q:  tensor([[0.2422, 0.3105, 0.3854, 0.3030]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  16 256   8]\n",
      " [  2   0 512   8]\n",
      " [  0   0   4   2]\n",
      " [  0   0   0   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  16 256   8]\n",
      " [  2   0 512   8]\n",
      " [  0   0   4   2]\n",
      " [  0   0   0   2]]\n",
      "Q:  tensor([[0.9692, 0.8802, 0.3220, 0.1409]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  0   0 256   8]\n",
      " [  4   0 512  16]\n",
      " [  2  16   4   4]]\n",
      "Reward: 20 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  0   0 256   8]\n",
      " [  4   0 512  16]\n",
      " [  2  16   4   4]]\n",
      "Q:  tensor([[-0.0322,  0.2305,  0.9582,  0.5655]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  2   0 256   8]\n",
      " [  0   4 512  16]\n",
      " [  0   2  16   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  2   0 256   8]\n",
      " [  0   4 512  16]\n",
      " [  0   2  16   8]]\n",
      "Q:  tensor([[0.2931, 0.3880, 0.0492, 0.2837]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4 256   2]\n",
      " [  2   2 512   8]\n",
      " [  0   0  16  16]\n",
      " [  0   0   0   8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4 256   2]\n",
      " [  2   2 512   8]\n",
      " [  0   0  16  16]\n",
      " [  0   0   0   8]]\n",
      "Q:  tensor([[0.6750, 0.8955, 0.8634, 0.8029]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4 256   2]\n",
      " [  0   2 512   8]\n",
      " [  4   0  16  16]\n",
      " [  0   0   0   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4 256   2]\n",
      " [  0   2 512   8]\n",
      " [  4   0  16  16]\n",
      " [  0   0   0   8]]\n",
      "Q:  tensor([[0.6423, 0.7128, 0.7151, 0.7532]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8 256   2   0]\n",
      " [  2 512   8   0]\n",
      " [  4  32   0   0]\n",
      " [  8   2   0   0]]\n",
      "Reward: 40 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8 256   2   0]\n",
      " [  2 512   8   0]\n",
      " [  4  32   0   0]\n",
      " [  8   2   0   0]]\n",
      "Q:  tensor([[ 0.1871, -0.0269,  0.1856, -0.2916]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8 256   0   0]\n",
      " [  2 512   0   2]\n",
      " [  4  32   2   0]\n",
      " [  8   2   8   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8 256   0   0]\n",
      " [  2 512   0   2]\n",
      " [  4  32   2   0]\n",
      " [  8   2   8   0]]\n",
      "Q:  tensor([[0.3020, 0.3445, 0.4501, 0.2506]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   8 256]\n",
      " [  0   2 512   2]\n",
      " [  0   4  32   2]\n",
      " [  2   8   2   8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   8 256]\n",
      " [  0   2 512   2]\n",
      " [  0   4  32   2]\n",
      " [  2   8   2   8]]\n",
      "Q:  tensor([[0.7404, 0.9118, 0.0896, 0.3976]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   8 256]\n",
      " [  0   4 512   4]\n",
      " [  0   8  32   8]\n",
      " [  0   2   2   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   8 256]\n",
      " [  0   4 512   4]\n",
      " [  0   8  32   8]\n",
      " [  0   2   2   0]]\n",
      "Q:  tensor([[0.3644, 0.0803, 0.7162, 0.9434]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8 256   0]\n",
      " [  4 512   4   0]\n",
      " [  8  32   8   0]\n",
      " [  4   4   0   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8 256   0]\n",
      " [  4 512   4   0]\n",
      " [  8  32   8   0]\n",
      " [  4   4   0   0]]\n",
      "Q:  tensor([[0.7512, 0.9021, 0.8087, 0.9239]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8 256   0]\n",
      " [  4 512   4   0]\n",
      " [  8  32   8   0]\n",
      " [  8   0   0   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8 256   0]\n",
      " [  4 512   4   0]\n",
      " [  8  32   8   0]\n",
      " [  8   0   0   2]]\n",
      "Q:  tensor([[0.8117, 0.8346, 0.1523, 0.3596]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   8 256   2]\n",
      " [ 16 512   4   0]\n",
      " [  8  32   8   0]\n",
      " [  0   0   4   0]]\n",
      "Reward: 24 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   8 256   2]\n",
      " [ 16 512   4   0]\n",
      " [  8  32   8   0]\n",
      " [  0   0   4   0]]\n",
      "Q:  tensor([[0.3658, 0.1497, 0.8428, 0.8412]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  16 256   2]\n",
      " [  0  16 512   4]\n",
      " [  0   8  32   8]\n",
      " [  0   0   0   4]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  16 256   2]\n",
      " [  0  16 512   4]\n",
      " [  0   8  32   8]\n",
      " [  0   0   0   4]]\n",
      "Q:  tensor([[ 0.8941,  0.7738, -0.1002,  0.1702]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  2   0 256   4]\n",
      " [  0  32 512   8]\n",
      " [  2   8  32   4]]\n",
      "Reward: 32 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  2   0 256   4]\n",
      " [  0  32 512   8]\n",
      " [  2   8  32   4]]\n",
      "Q:  tensor([[0.7243, 0.7458, 0.2480, 0.3847]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32 256   2]\n",
      " [  4   8 512   4]\n",
      " [  0   0  32   8]\n",
      " [  0   0   0   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32 256   2]\n",
      " [  4   8 512   4]\n",
      " [  0   0  32   8]\n",
      " [  0   0   0   4]]\n",
      "Q:  tensor([[0.8770, 0.7716, 0.1967, 0.2799]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  0   0 256   4]\n",
      " [  2  32 512   8]\n",
      " [  8   8  32   4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  0   0 256   4]\n",
      " [  2  32 512   8]\n",
      " [  8   8  32   4]]\n",
      "Q:  tensor([[0.1182, 0.3664, 0.8846, 0.7903]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   0   2]\n",
      " [  2   0 256   4]\n",
      " [  2  32 512   8]\n",
      " [  0  16  32   4]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   0   2]\n",
      " [  2   0 256   4]\n",
      " [  2  32 512   8]\n",
      " [  0  16  32   4]]\n",
      "Q:  tensor([[0.7109, 0.7536, 0.2251, 0.3263]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32 256   2]\n",
      " [  0  16 512   4]\n",
      " [  0   0  32   8]\n",
      " [  0   2   0   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32 256   2]\n",
      " [  0  16 512   4]\n",
      " [  0   0  32   8]\n",
      " [  0   2   0   4]]\n",
      "Q:  tensor([[0.3420, 0.1661, 0.1668, 0.3809]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32 256   2]\n",
      " [ 16 512   4   2]\n",
      " [ 32   8   0   0]\n",
      " [  2   4   0   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32 256   2]\n",
      " [ 16 512   4   2]\n",
      " [ 32   8   0   0]\n",
      " [  2   4   0   0]]\n",
      "Q:  tensor([[ 0.9052,  0.4720,  0.0649, -0.0917]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   0   2]\n",
      " [ 16 512   0   0]\n",
      " [ 32   8 256   0]\n",
      " [  2   4   4   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   0   2]\n",
      " [ 16 512   0   0]\n",
      " [ 32   8 256   0]\n",
      " [  2   4   4   4]]\n",
      "Q:  tensor([[0.2019, 0.0968, 0.7837, 0.9510]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   2   0]\n",
      " [ 16 512   0   0]\n",
      " [ 32   8 256   2]\n",
      " [  2   8   4   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   2   0]\n",
      " [ 16 512   0   0]\n",
      " [ 32   8 256   2]\n",
      " [  2   8   4   0]]\n",
      "Q:  tensor([[ 8.6892e-01,  9.8460e-01,  2.5604e-01, -8.7567e-04]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4  32   2   2]\n",
      " [ 16 512 256   0]\n",
      " [ 32  16   4   0]\n",
      " [  2   2   0   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4  32   2   2]\n",
      " [ 16 512 256   0]\n",
      " [ 32  16   4   0]\n",
      " [  2   2   0   0]]\n",
      "Q:  tensor([[0.3875, 0.1593, 0.9630, 0.7648]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   4  32   4]\n",
      " [  0  16 512 256]\n",
      " [  0  32  16   4]\n",
      " [  2   0   0   4]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   4  32   4]\n",
      " [  0  16 512 256]\n",
      " [  0  32  16   4]\n",
      " [  2   0   0   4]]\n",
      "Q:  tensor([[0.7462, 0.8392, 0.1525, 0.3034]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4  32   4]\n",
      " [  0  16 512 256]\n",
      " [  2  32  16   8]\n",
      " [  0   0   0   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4  32   4]\n",
      " [  0  16 512 256]\n",
      " [  2  32  16   8]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[ 0.6086,  0.7169, -0.0419,  0.3627]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4  32   4]\n",
      " [  0  16 512 256]\n",
      " [  2  32  16   8]\n",
      " [  0   0   0   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4  32   4]\n",
      " [  0  16 512 256]\n",
      " [  2  32  16   8]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[0.1307, 0.2026, 0.8491, 0.7825]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8  32   4]\n",
      " [  0  16 512 256]\n",
      " [  2  32  16   8]\n",
      " [  0   0   0   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   8  32   4]\n",
      " [  0  16 512 256]\n",
      " [  2  32  16   8]\n",
      " [  0   0   0   0]]\n",
      "Q:  tensor([[0.5954, 0.5631, 0.1229, 0.3151]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   0   0]\n",
      " [  0   8  32   4]\n",
      " [  0  16 512 256]\n",
      " [  4  32  16   8]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   0   0]\n",
      " [  0   8  32   4]\n",
      " [  0  16 512 256]\n",
      " [  4  32  16   8]]\n",
      "Q:  tensor([[-0.5422,  0.1844,  0.1823,  0.2908]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   4   0]\n",
      " [  8  32   4   0]\n",
      " [ 16 512 256   0]\n",
      " [  4  32  16   8]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   4   0]\n",
      " [  8  32   4   0]\n",
      " [ 16 512 256   0]\n",
      " [  4  32  16   8]]\n",
      "Q:  tensor([[0.5507, 0.7530, 0.3305, 0.0869]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   8   8]\n",
      " [  8 512 256   0]\n",
      " [ 16  32  16   2]\n",
      " [  4   0   0   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   8   8]\n",
      " [  8 512 256   0]\n",
      " [ 16  32  16   2]\n",
      " [  4   0   0   0]]\n",
      "Q:  tensor([[0.4227, 0.2711, 0.8316, 0.8737]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32  16   0]\n",
      " [  8 512 256   2]\n",
      " [ 16  32  16   2]\n",
      " [  4   0   0   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32  16   0]\n",
      " [  8 512 256   2]\n",
      " [ 16  32  16   2]\n",
      " [  4   0   0   0]]\n",
      "Q:  tensor([[0.9063, 0.5838, 0.3609, 0.1587]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   0   2]\n",
      " [  8  32  16   0]\n",
      " [ 16 512 256   0]\n",
      " [  4  32  16   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   0   2]\n",
      " [  8  32  16   0]\n",
      " [ 16 512 256   0]\n",
      " [  4  32  16   4]]\n",
      "Q:  tensor([[0.2250, 0.3549, 0.6559, 0.6704]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   0   0]\n",
      " [  8  32  16   0]\n",
      " [ 16 512 256   2]\n",
      " [  4  32  16   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   0   0]\n",
      " [  8  32  16   0]\n",
      " [ 16 512 256   2]\n",
      " [  4  32  16   4]]\n",
      "Q:  tensor([[-0.3729,  0.1608,  0.2076, -0.2370]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2   4]\n",
      " [  0   8  32  16]\n",
      " [ 16 512 256   2]\n",
      " [  4  32  16   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2   4]\n",
      " [  0   8  32  16]\n",
      " [ 16 512 256   2]\n",
      " [  4  32  16   4]]\n",
      "Q:  tensor([[-0.2618,  0.2107, -0.2576,  0.3149]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4   2   0]\n",
      " [  8  32  16   0]\n",
      " [ 16 512 256   2]\n",
      " [  4  32  16   4]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4   2   0]\n",
      " [  8  32  16   0]\n",
      " [ 16 512 256   2]\n",
      " [  4  32  16   4]]\n",
      "Q:  tensor([[-0.1583,  0.4749,  0.2251, -0.2112]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   4   2   2]\n",
      " [  8  32  16   4]\n",
      " [ 16 512 256   2]\n",
      " [  4  32  16   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   4   2   2]\n",
      " [  8  32  16   4]\n",
      " [ 16 512 256   2]\n",
      " [  4  32  16   0]]\n",
      "Q:  tensor([[0.3901, 0.0420, 0.9284, 0.8750]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   4   4]\n",
      " [  8  32  16   4]\n",
      " [ 16 512 256   2]\n",
      " [  0   4  32  16]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   4   4]\n",
      " [  8  32  16   4]\n",
      " [ 16 512 256   2]\n",
      " [  0   4  32  16]]\n",
      "Q:  tensor([[0.7104, 0.8177, 0.7280, 0.7367]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   2   4   8]\n",
      " [  8  32  16   2]\n",
      " [ 16 512 256  16]\n",
      " [  2   4  32   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   2   4   8]\n",
      " [  8  32  16   2]\n",
      " [ 16 512 256  16]\n",
      " [  2   4  32   0]]\n",
      "Q:  tensor([[ 0.2843, -0.0259,  0.8931,  1.0087]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   4   8   0]\n",
      " [  8  32  16   2]\n",
      " [ 16 512 256  16]\n",
      " [  2   4  32   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   4   8   0]\n",
      " [  8  32  16   2]\n",
      " [ 16 512 256  16]\n",
      " [  2   4  32   2]]\n",
      "Q:  tensor([[-0.2306,  0.5399,  0.6150,  1.0620]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8   8   2   0]\n",
      " [  8  32  16   2]\n",
      " [ 16 512 256  16]\n",
      " [  2   4  32   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8   8   2   0]\n",
      " [  8  32  16   2]\n",
      " [ 16 512 256  16]\n",
      " [  2   4  32   2]]\n",
      "Q:  tensor([[0.6634, 0.9491, 0.8058, 0.7879]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   8   2   2]\n",
      " [ 16  32  16  16]\n",
      " [  2 512 256   2]\n",
      " [  2   4  32   0]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   8   2   2]\n",
      " [ 16  32  16  16]\n",
      " [  2 512 256   2]\n",
      " [  2   4  32   0]]\n",
      "Q:  tensor([[0.7457, 0.8945, 0.9118, 0.8417]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0  16   8   4]\n",
      " [  4  16  32  32]\n",
      " [  2 512 256   2]\n",
      " [  0   2   4  32]]\n",
      "Reward: 36 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0  16   8   4]\n",
      " [  4  16  32  32]\n",
      " [  2 512 256   2]\n",
      " [  0   2   4  32]]\n",
      "Q:  tensor([[0.7156, 0.8429, 0.8226, 0.9784]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   8   4   2]\n",
      " [  4  16  64   0]\n",
      " [  2 512 256   2]\n",
      " [  2   4  32   0]]\n",
      "Reward: 64 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   8   4   2]\n",
      " [  4  16  64   0]\n",
      " [  2 512 256   2]\n",
      " [  2   4  32   0]]\n",
      "Q:  tensor([[0.8596, 0.9371, 0.4375, 0.4279]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[ 16   8   4   4]\n",
      " [  4  16  64   0]\n",
      " [  4 512 256   2]\n",
      " [  0   4  32   0]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[ 16   8   4   4]\n",
      " [  4  16  64   0]\n",
      " [  4 512 256   2]\n",
      " [  0   4  32   0]]\n",
      "Q:  tensor([[0.8856, 0.8705, 0.8067, 0.8550]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8   4   0]\n",
      " [  0  16  64   0]\n",
      " [ 16 512 256   4]\n",
      " [  8   4  32   2]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   8   4   0]\n",
      " [  0  16  64   0]\n",
      " [ 16 512 256   4]\n",
      " [  8   4  32   2]]\n",
      "Q:  tensor([[ 0.1385,  0.4729,  0.3373, -0.0166]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8   4   4]\n",
      " [ 16  16  64   2]\n",
      " [  8 512 256   0]\n",
      " [  2   4  32   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   8   4   4]\n",
      " [ 16  16  64   2]\n",
      " [  8 512 256   0]\n",
      " [  2   4  32   0]]\n",
      "Q:  tensor([[0.2379, 0.5536, 0.8342, 0.8904]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8   8   0]\n",
      " [ 32  64   2   0]\n",
      " [  8 512 256   2]\n",
      " [  2   4  32   0]]\n",
      "Reward: 40 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   8   8   0]\n",
      " [ 32  64   2   0]\n",
      " [  8 512 256   2]\n",
      " [  2   4  32   0]]\n",
      "Q:  tensor([[0.2938, 0.3209, 0.9861, 0.6164]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   0   2  16]\n",
      " [  0  32  64   2]\n",
      " [  8 512 256   2]\n",
      " [  2   2   4  32]]\n",
      "Reward: 16 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   0   2  16]\n",
      " [  0  32  64   2]\n",
      " [  8 512 256   2]\n",
      " [  2   2   4  32]]\n",
      "Q:  tensor([[0.8341, 0.8642, 0.8794, 0.8198]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   0   2  16]\n",
      " [  0  32  64   2]\n",
      " [  8 512 256   2]\n",
      " [  0   4   4  32]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2   0   2  16]\n",
      " [  0  32  64   2]\n",
      " [  8 512 256   2]\n",
      " [  0   4   4  32]]\n",
      "Q:  tensor([[0.8547, 0.9254, 0.7746, 0.8889]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2  32   2  16]\n",
      " [  8 512  64   4]\n",
      " [  0   4 256  32]\n",
      " [  0   0   4   2]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  2  32   2  16]\n",
      " [  8 512  64   4]\n",
      " [  0   4 256  32]\n",
      " [  0   0   4   2]]\n",
      "Q:  tensor([[ 0.3757, -0.0445, -0.2411,  0.3707]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   2   2  16]\n",
      " [  0  32  64   4]\n",
      " [  2 512 256  32]\n",
      " [  8   4   4   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   2   2  16]\n",
      " [  0  32  64   4]\n",
      " [  2 512 256  32]\n",
      " [  8   4   4   2]]\n",
      "Q:  tensor([[0.3317, 0.3069, 0.9580, 0.7523]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   0   4  16]\n",
      " [  0  32  64   4]\n",
      " [  2 512 256  32]\n",
      " [  0   8   8   2]]\n",
      "Reward: 12 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   0   4  16]\n",
      " [  0  32  64   4]\n",
      " [  2 512 256  32]\n",
      " [  0   8   8   2]]\n",
      "Q:  tensor([[0.3360, 0.4145, 0.7447, 0.7891]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8  16   0   2]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256  32]\n",
      " [ 16   2   0   0]]\n",
      "Reward: 24 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8  16   0   2]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256  32]\n",
      " [ 16   2   0   0]]\n",
      "Q:  tensor([[0.3092, 0.3238, 0.2536, 0.3203]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8  16   4   2]\n",
      " [ 32  64 256  32]\n",
      " [  2 512   2   0]\n",
      " [ 16   2   0   0]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8  16   4   2]\n",
      " [ 32  64 256  32]\n",
      " [  2 512   2   0]\n",
      " [ 16   2   0   0]]\n",
      "Q:  tensor([[ 0.3173, -0.1079,  0.3111, -0.2460]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  8  16   2   0]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256   2]\n",
      " [ 16   2   2  32]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  8  16   2   0]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256   2]\n",
      " [ 16   2   2  32]]\n",
      "Q:  tensor([[0.3739, 0.3710, 0.8559, 0.8282]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  0   8  16   2]\n",
      " [  0  32  64   4]\n",
      " [  2 512 256   2]\n",
      " [  2  16   4  32]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  0   8  16   2]\n",
      " [  0  32  64   4]\n",
      " [  2 512 256   2]\n",
      " [  2  16   4  32]]\n",
      "Q:  tensor([[0.6004, 0.7444, 0.0458, 0.3011]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8  16   2]\n",
      " [  0  32  64   4]\n",
      " [  2 512 256   2]\n",
      " [  0  16   4  32]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8  16   2]\n",
      " [  0  32  64   4]\n",
      " [  2 512 256   2]\n",
      " [  0  16   4  32]]\n",
      "Q:  tensor([[ 0.0651,  0.1295, -0.0824,  0.4091]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8  16   2]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256   2]\n",
      " [ 16   4  32   2]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8  16   2]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256   2]\n",
      " [ 16   4  32   2]]\n",
      "Q:  tensor([[0.7824, 0.7765, 0.6409, 0.3384]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8  16   2]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256   2]\n",
      " [ 16   4  32   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8  16   2]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256   2]\n",
      " [ 16   4  32   4]]\n",
      "Q:  tensor([[0.8674, 0.8412, 0.4057, 0.3983]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8  16   2]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256   4]\n",
      " [ 16   4  32   4]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8  16   2]\n",
      " [ 32  64   4   0]\n",
      " [  2 512 256   4]\n",
      " [ 16   4  32   4]]\n",
      "Q:  tensor([[0.8115, 0.7568, 0.3925, 0.1867]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8  16   0]\n",
      " [ 32  64   4   2]\n",
      " [  2 512 256   2]\n",
      " [ 16   4  32   8]]\n",
      "Reward: 8 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8  16   0]\n",
      " [ 32  64   4   2]\n",
      " [  2 512 256   2]\n",
      " [ 16   4  32   8]]\n",
      "Q:  tensor([[ 0.6901,  0.7727,  0.5137, -0.0145]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8  16   4]\n",
      " [ 32  64   4   8]\n",
      " [  2 512 256   2]\n",
      " [ 16   4  32   0]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8  16   4]\n",
      " [ 32  64   4   8]\n",
      " [  2 512 256   2]\n",
      " [ 16   4  32   0]]\n",
      "Q:  tensor([[ 0.0960, -0.2568,  0.3515, -0.2378]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8  16   4]\n",
      " [ 32  64   4   8]\n",
      " [  2 512 256   2]\n",
      " [  2  16   4  32]]\n",
      "Reward: 0 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8  16   4]\n",
      " [ 32  64   4   8]\n",
      " [  2 512 256   2]\n",
      " [  2  16   4  32]]\n",
      "Q:  tensor([[ 0.4714,  0.6466, -0.1388,  0.1725]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  4   8  16   4]\n",
      " [ 32  64   4   8]\n",
      " [  4 512 256   2]\n",
      " [  4  16   4  32]]\n",
      "Reward: 4 Done: False\n",
      "\n",
      "\n",
      "State:\n",
      "[[  4   8  16   4]\n",
      " [ 32  64   4   8]\n",
      " [  4 512 256   2]\n",
      " [  4  16   4  32]]\n",
      "Q:  tensor([[ 0.4623, -0.0334, -0.1787, -0.1869]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[[  2   8  16   4]\n",
      " [  4  64   4   8]\n",
      " [ 32 512 256   2]\n",
      " [  8  16   4  32]]\n",
      "Reward: -100 Done: True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_steps = 0\n",
    "for _ in range(1000):\n",
    "    print('State:')\n",
    "    print(decode_board(state))\n",
    "    Q = policy_net(state.cuda())\n",
    "    print('Q: ', Q)\n",
    "    action = Q.argmax().item()\n",
    "    state, reward, done = env.action(action)\n",
    "    while reward == -10:\n",
    "        Q[0, action] = float('-inf')\n",
    "        action = Q.argmax().item()\n",
    "        state, reward, done = env.action(action)\n",
    "    print(decode_board(state))\n",
    "    print('Reward:', reward, 'Done:', done)\n",
    "    print('\\n')\n",
    "    N_steps+=1\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2935.0625, 2907.4143, 2930.1863, 2944.1321]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net(state.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 4, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.tensor(env.reset(), dtype=torch.float32, device=device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 2., 0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[554.8129, 552.2155, 553.0561, 554.3870]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (fc1): Linear(in_features=4, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "  (fc4): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (fc5): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (fc6): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc7): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc8): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc9): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 21])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.02856593, -0.04845341, -0.00792314,  0.02017498], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02849323,  0.04839472,  0.00306607, -0.00299951], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/anaconda3/lib/python3.12/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/ilya/Desktop/RL/RL_2048/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/ilya/Desktop/RL/RL_2048/video/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/ilya/Desktop/RL/RL_2048/video/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/ilya/Desktop/RL/RL_2048/video/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m next_state, reward, done, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     14\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m---> 15\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gymnasium/wrappers/record_video.py:223\u001b[0m, in \u001b[0;36mRecordVideo.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m recorded_frames \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gymnasium/core.py:471\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gymnasium/core.py:471\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gymnasium/wrappers/order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gymnasium/wrappers/env_checker.py:67\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gymnasium/envs/classic_control/cartpole.py:299\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m gfxdraw\u001b[38;5;241m.\u001b[39mhline(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen_width, carty, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen\u001b[38;5;241m.\u001b[39mblit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    301\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "env.reset()\n",
    "#env = preprocess_env(env)  # method with some other wrappers\n",
    "env = RecordVideo(env, 'video', episode_trigger=lambda x: x == 2)\n",
    "env.start_video_recorder()\n",
    "\n",
    "for episode in range(4):\n",
    "        state = env.reset()[0]\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = policy_net(torch.tensor(state, device='cuda').unsqueeze(0)).argmax().item()\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "            state = next_state\n",
    "            env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(policy_net.state_dict(), 'policy_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1167935/4165716865.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_net.load_state_dict(torch.load('policy_net.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net.load_state_dict(torch.load('policy_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2., 4., 8., 0., 0., 2., 4., 0., 2., 0., 4., 0., 0., 0., 0.]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990004498800211"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.923002481460571"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.685814142227173"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
